<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>37.2° Blog | 37.2° Blog</title><meta name="author" content="Dongnian"><meta name="copyright" content="Dongnian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="deepspeed介绍 - wolai 笔记1.Deepspeed分布式计算环境中，主节点负责协调其他节点和进程的工作pytorch官方提供的分布式训练工具Accelerate只支持nvlink，而T4，3090这类显卡是PIX ，检测方式：nvidia-smi topo -m；deepspeed支持更大规模的模型训练混合精度训练ZeRO可以减少内存占用，优化大模型训练，将模型参数分成了三个部分">
<meta property="og:type" content="website">
<meta property="og:title" content="37.2° Blog">
<meta property="og:url" content="https://wdndev.github.io/note/llm/llm_concept/04.%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/deepspeed%E4%BB%8B%E7%BB%8D/deepspeed%E4%BB%8B%E7%BB%8D.html">
<meta property="og:site_name" content="37.2° Blog">
<meta property="og:description" content="deepspeed介绍 - wolai 笔记1.Deepspeed分布式计算环境中，主节点负责协调其他节点和进程的工作pytorch官方提供的分布式训练工具Accelerate只支持nvlink，而T4，3090这类显卡是PIX ，检测方式：nvidia-smi topo -m；deepspeed支持更大规模的模型训练混合精度训练ZeRO可以减少内存占用，优化大模型训练，将模型参数分成了三个部分">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://wdndev.github.io/img/wdn_icon.png">
<meta property="article:published_time" content="2024-12-08T03:56:28.030Z">
<meta property="article:modified_time" content="2024-12-08T03:56:28.030Z">
<meta property="article:author" content="Dongnian">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wdndev.github.io/img/wdn_icon.png"><link rel="shortcut icon" href="/img/wdn_icon.png"><link rel="canonical" href="https://wdndev.github.io/note/llm/llm_concept/04.%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/deepspeed%E4%BB%8B%E7%BB%8D/deepspeed%E4%BB%8B%E7%BB%8D.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: 'days',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: Dongnian","link":"Link: ","source":"Source: 37.2° Blog","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '37.2° Blog',
  isPost: false,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-12-08 11:56:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/wdn_icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">87</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Content</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/paper_reading/pr_content"><i class="fa-fw fas fa-newspaper"></i><span> Paper</span></a></li><li><a class="site-page child" href="/llms/llms_idx"><i class="fa-fw fa-solid fa-magnifying-glass"></i><span> LLMs</span></a></li><li><a class="site-page child" href="/jupyter"><i class="fa-fw fa-solid fa-file"></i><span> Jupyter</span></a></li><li><a class="site-page child" href="/note"><i class="fa-fw fa-regular fa-bookmark"></i><span> Note</span></a></li><li><a class="site-page child" href="/dsa/dsa_idx"><i class="fa-fw fas fa-tree"></i><span> Algorithm</span></a></li><li><a class="site-page child" href="/program_language/pl_idx"><i class="fa-fw fas fa-code"></i><span> PLs</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img fixed" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="37.2° Blog"><span class="site-name">37.2° Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Content</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/paper_reading/pr_content"><i class="fa-fw fas fa-newspaper"></i><span> Paper</span></a></li><li><a class="site-page child" href="/llms/llms_idx"><i class="fa-fw fa-solid fa-magnifying-glass"></i><span> LLMs</span></a></li><li><a class="site-page child" href="/jupyter"><i class="fa-fw fa-solid fa-file"></i><span> Jupyter</span></a></li><li><a class="site-page child" href="/note"><i class="fa-fw fa-regular fa-bookmark"></i><span> Note</span></a></li><li><a class="site-page child" href="/dsa/dsa_idx"><i class="fa-fw fas fa-tree"></i><span> Algorithm</span></a></li><li><a class="site-page child" href="/program_language/pl_idx"><i class="fa-fw fas fa-code"></i><span> PLs</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="page"><h1 class="page-title"></h1><div id="article-container"><!DOCTYPE html>
<html lang="zh-Hans-CN"><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=Edge"/><link rel="stylesheet" type="text/css" href="../../css/modern-norm.min.css"/><link rel="stylesheet" type="text/css" href="../../css/prism.min.css"/><link rel="stylesheet" type="text/css" href="../../css/katex.min.css"/><link rel="stylesheet" type="text/css" href="../../css/wolai.css"/><title>deepspeed介绍 - wolai 笔记</title><link rel="shortcut icon" href="data:image/svg+xml,%3Csvg xmlns=&apos;http://www.w3.org/2000/svg&apos; viewBox=&apos;0 0 800 800&apos;%3E%3Cdefs%3E%3Cstyle%3E.cls-1%7Bfill:%23fff;%7D%3C/style%3E%3C/defs%3E%3Cg%3E%3Cpath class=&apos;cls-1&apos; d=&apos;M610.08,0c66,0,90,6.88,114.13,19.79a134.62,134.62,0,0,1,56,56l2.28,4.4C793.93,103,800,127.88,800,189.92V610.08l-.08,11.56c-.78,57.38-7.58,79.89-19.71,102.57a134.62,134.62,0,0,1-56,56l-4.4,2.28C697,793.93,672.12,800,610.08,800H189.92l-11.56-.08c-57.38-.78-79.89-7.58-102.57-19.71a134.62,134.62,0,0,1-56-56l-2.28-4.4C6.44,697.75.4,673.72,0,616L0,189.92c0-66,6.88-90,19.79-114.13a134.62,134.62,0,0,1,56-56l4.4-2.28C102.25,6.44,126.28.4,184,0Z&apos;/%3E%3Cpath d=&apos;M610.08,0c66,0,90,6.88,114.13,19.79a134.62,134.62,0,0,1,56,56l2.28,4.4C793.93,103,800,127.88,800,189.92V610.08l-.08,11.56c-.78,57.38-7.58,79.89-19.71,102.57a134.62,134.62,0,0,1-56,56l-4.4,2.28C697,793.93,672.12,800,610.08,800H189.92l-11.56-.08c-57.38-.78-79.89-7.58-102.57-19.71a134.62,134.62,0,0,1-56-56l-2.28-4.4C6.44,697.75.4,673.72,0,616L0,189.92c0-66,6.88-90,19.79-114.13a134.62,134.62,0,0,1,56-56l4.4-2.28C102.25,6.44,126.28.4,184,0Zm4.72,88.9H185.2L172.42,89c-32.78.62-43.68,3.24-54.71,9.14a45.84,45.84,0,0,0-19.54,19.54c-6.61,12.36-9.11,24.55-9.27,67.49V614.8L89,627.58c.62,32.78,3.24,43.68,9.14,54.71a45.84,45.84,0,0,0,19.54,19.54c12.36,6.61,24.55,9.11,67.49,9.27H610.08c46.79,0,59.41-2.44,72.21-9.28a45.84,45.84,0,0,0,19.54-19.54c6.61-12.36,9.11-24.55,9.27-67.49V189.92c0-46.79-2.44-59.41-9.28-72.21a45.84,45.84,0,0,0-19.54-19.54C669.93,91.56,657.74,89.06,614.8,88.9ZM233.33,493.33A73.34,73.34,0,1,1,160,566.67,73.35,73.35,0,0,1,233.33,493.33Z&apos;/%3E%3C/g%3E%3C/svg%3E"></link></head><body><header><div class="image"></div><div class="title"><div class="banner"><div class="icon"></div></div><div data-title="deepspeed介绍" class="main-title"></div></div></header><article><h2 id="t3W59DWgAv41PLZGSrUnRz" class="wolai-block"><span class="inline-wrap">1.Deepspeed</span></h2><ul class="wolai-block"><li id="dieCJuX7ga4fB99zef5ghy"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">分布式计算环境中，主节点负责协调其他节点和进程的工作</span></li><li id="ohfqWY5cA1X8nGWBzwUQyW"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">pytorch<span class="jill"></span>官方提供的分布式训练工具<span class="jill"></span>Accelerate<span class="jill"></span>只支持<span class="jill"></span>nvlink，而<span class="jill"></span>T4，3090<span class="jill"></span>这类显卡是<span class="jill"></span>PIX ，检测方式：nvidia-smi topo -m；deepspeed<span class="jill"></span>支持更大规模的模型训练</span></li><li id="ndiDAsHe2GVn5H86K6RnGm"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">混合精度训练</span></li><li id="w9ZiheMKHEF2tfX2ZKN3Xc"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">ZeRO<span class="jill"></span>可以减少内存占用，优化大模型训练，将模型参数分成了三个部分：Optimizer States、Gradient 和 Model Parameter。在使用 ZeRO 进行分布式训练时，可以选择 ZeRO-Offload 和 ZeRO-Stage3 等不同的优化技术。</span></li></ul><div id="q8Uak4uQzmzvBDiBnQ1q1v" class="wolai-block wolai-text"><div><span class="inline-wrap">大模型（LLM）在训练时往往需要大量内存来存储中间激活、权重等参数，百亿模型甚至无法在单个 GPU<span class="jill"></span>上进行训练，使得模型训练在某些情况下非常低效和不可能。这就需要进行多卡，或者多节点分布式训练。</span></div></div><div id="enCQzcwgrf4iYHtqbHGhG7" class="wolai-block wolai-text"><div><span class="inline-wrap">在大规模深度学习</span><span class="inline-wrap"><a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=模型训练&amp;spm=1001.2101.3001.7020"><span>模型训练</span></a></span><span class="inline-wrap">中有个主要范式：</span></div></div><ul class="wolai-block"><li id="q4k1tLZyH8n7edzZDHehAj"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">数据并行</span></li><li id="qUHtFa3iD9AcV1u66JUN25"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">模型并行</span></li></ul><div id="aQYEgnWHGyqAT4S6o2TDBi" class="wolai-block wolai-text"><div><span class="inline-wrap">目前训练超大规模语言模型技术路线：GPU + PyTorch + Megatron-LM + DeepSpeed</span></div></div><div id="aEYaMxNuBQPhwovm6TMiAu" class="wolai-block wolai-text"><div><span class="inline-wrap">DeepSpeed<span class="jill"></span>是由<span class="jill"></span>Microsoft<span class="jill"></span>提供的分布式训练工具，旨</span><span class="yellow inline-wrap"><b>在支持更大规模的模型和提供更多的优化策略和工具</b></span><span class="inline-wrap">。与其他框架相比，</span><span class="red inline-wrap"><b>DeepSpeed<span class="jill"></span>支持更大规模的模型和提供更多的优化策略和工具。其中，主要优势在于支持更大规模的模型、提供了更多的优化策略和工具（例如 ZeRO 和 Offload 等）</b></span></div></div><ul class="wolai-block"><li id="w7skbk2HX4tJLvuR75tDUu"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>用 3D 并行化实现万亿参数模型训练</b></span><span class="inline-wrap"><b>：</b></span><span class="inline-wrap">  DeepSpeed 实现了三种并行方法的灵活组合：ZeRO 支持的数据并行，流水线并行和张量切片模型并行。3D 并行性适应了不同工作负载的需求，以支持具有</span><span class="inline-wrap"><b>万亿</b></span><span class="inline-wrap">参数的</span><span class="inline-wrap"><b>超大型模型</b></span><span class="inline-wrap">，同时实现了近乎完美的显存扩展性和吞吐量扩展效率。此外，其提高的通信效率使用户可以在网络带宽有限的常规群集上以 2-7 倍的速度训练有数十亿参数的模型。</span></li><li id="vKzJ3YgkGqyTk3Xx4j2V7C"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>ZeRO-Offload 使 GPU 单卡能够训练 10 倍大的模型</b></span><span class="inline-wrap"><b>：</b></span><span class="inline-wrap">  <span class="jill"></span>为了同时利用 CPU 和 GPU 内存来训练大型模型，我们扩展了 ZeRO-2。我们的用户在使用带有</span><span class="inline-wrap"><b>单张英伟达 V100 GPU</b></span><span class="inline-wrap"> <span class="jill"></span>的机器时，可以在不耗尽显存的情况下运行</span><span class="inline-wrap"><b>多达 130 亿个参数的模型</b></span><span class="inline-wrap">，模型规模扩展至现有方法的<span class="jill"></span>10<span class="jill"></span>倍，并保持有竞争力的吞吐量。此功能使数十亿参数的模型训练更加大众化，，并为许多深度学习从业人员打开了一扇探索更大更好的模型的窗户。</span></li><li id="pehvR7TD5FpqKZTgGDEZGj"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>通过 DeepSpeed Sparse Attention 用<span class="jill"></span>6<span class="jill"></span>倍速度执行<span class="jill"></span>10<span class="jill"></span>倍长的序列</b></span><span class="inline-wrap"><b>：</b></span><span class="inline-wrap">  DeepSpeed<span class="jill"></span>提供了稀疏 attention kernel ——一种工具性技术，可支持长序列的模型输入，包括文本输入，图像输入和语音输入。与经典的稠密 Transformer 相比，它支持的</span><span class="inline-wrap"><b>输入序列长一个数量级</b></span><span class="inline-wrap">，并在保持相当的精度下获得最高 6 倍的执行速度提升。它还比最新的稀疏实现快 1.5–3 倍。此外，我们的稀疏 kernel 灵活支持稀疏格式，使用户能够通过自定义稀疏结构进行创新。</span></li><li id="cSYKdC26Z4tMSqJ9Mk8kPF"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>1 比特 Adam 减少 5 倍通信量</b></span><span class="inline-wrap"><b>：</b></span><span class="inline-wrap">  Adam 是一个在大规模深度学习模型训练场景下的有效的（也许是最广为应用的）优化器。然而，它与通信效率优化算法往往不兼容。因此，在跨设备进行分布式扩展时，通信开销可能成为瓶颈。我们推出了一种 1 比特 Adam 新算法，以及其高效实现。该算法</span><span class="inline-wrap"><b>最多可减少 5 倍通信量</b></span><span class="inline-wrap">，同时实现了与<span class="jill"></span>Adam<span class="jill"></span>相似的收敛率。在通信受限的场景下，我们观察到分布式训练速度提升了 3.5 倍，这使得该算法可以扩展到不同类型的 GPU 群集和网络环境。</span></li></ul><h3 id="tsSuzK6xhbyXSnsgBdABQs" class="wolai-block"><span class="inline-wrap"><b>1.1  基本概念</b></span></h3><ul class="wolai-block"><li id="4RX4Xe1Fyw6SSn1XMh27rU"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">在分布式计算环境中，需要理解几个非常基础的概念：</span><span class="inline-wrap"><code>节点编号</code></span><span class="inline-wrap">、</span><span class="inline-wrap"><code>全局进程编号</code></span><span class="inline-wrap">、</span><span class="inline-wrap"><code>局部进程编号</code></span><span class="inline-wrap">、</span><span class="inline-wrap"><code>全局总进程数和主节点</code></span><span class="inline-wrap">。其中，主节点负责协调所有其他节点和进程的工作，因此是整个系统的关键部分。</span></li><li id="h7qtnSBbajbPMUVbKSvX5j"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">DeepSpeed 还提供了 mpi、gloo 和 nccl 等通信策略，可以根据具体情况进行选择和配置。在使用 DeepSpeed 进行分布式训练时，</span><span class="yellow inline-wrap">可以根据具体情况选择合适的通信库</span><span class="inline-wrap">，例如在 CPU 集群上进行分布式训练，可以选择 mpi 和 gloo；如果是在 GPU 上进行分布式训练，可以选择 nccl。</span></li><li id="r3h2XjDzy4YUzo6hAaTTJL"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>ZeRO</code></span><span class="inline-wrap">（Zero Redundancy Optimizer）是</span><span class="yellow inline-wrap"><b>一种用于大规模训练优化的技术，主要是用来减少内存占用</b></span><span class="inline-wrap">。ZeRO 将模型参数分成了三个部分：Optimizer States、Gradient 和 Model Parameter。在使用 ZeRO 进行分布式训练时，可以选择 ZeRO-Offload 和 ZeRO-Stage3 等不同的优化技术。</span></li><li id="uRiokvDRuom4kM2fWkPi4h"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>混合精度训练</b></span><span class="inline-wrap">是指在训练过程中同时使用<span class="jill"></span>FP16（半精度浮点数）和<span class="jill"></span>FP32（单精度浮点数）两种精度的技术。使用<span class="jill"></span>FP16<span class="jill"></span>可以大大减少内存占用，从而可以训练更大规模的模型。在使用混合精度训练时，需要使用一些技术来解决可能出现的梯度消失和模型不稳定的问题，例如动态精度缩放和混合精度优化器等。</span></li><li id="erd3gaX9QTqnh1ZJXg7jrt"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">结合使用<span class="jill"></span>huggingface<span class="jill"></span>和<span class="jill"></span>deepspeed</span></li></ul><div id="32C7TCM8BK8SiR9y226WEd" class="wolai-block wolai-text"><div><span class="inline-wrap">在分布式计算环境中，有几个非常基础的概念需要理解：</span></div></div><ul class="wolai-block"><li id="UXp9C8pSdGNrjk3j3QnyL"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>节点编号（node_rank）</b></span><span class="inline-wrap">：分配给系统中每个节点的唯一标识符，用于区分不同计算机之间的通信。</span></li><li id="fr2coo3wjo463N2L9yyhpR"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>全局进程编号（rank）</b></span><span class="inline-wrap">：分配给整个系统中的每个进程的唯一标识符，用于区分不同进程之间的通信。</span></li><li id="pRYbGLDHDafAUGupcQ84zi"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>局部进程编号（local_rank）</b></span><span class="inline-wrap">：分配给单个节点内的每个进程的唯一标识符，用于区分同一节点内的不同进程之间的通信。</span></li><li id="fMzuhuwxoKabM1mugW6T28"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>全局总进程数（word_size）</b></span><span class="inline-wrap">：在整个系统中运行的所有进程的总数，用于确定可以并行完成多少工作以及需要完成任务所需的资源数量。</span></li><li id="rpbVE3mBjwkYfQ6LivRt4R"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>主节点（master_ip+master_port）</b></span><span class="inline-wrap">：在分布式计算环境中，主节点负责协调所有其他节点和进程的工作，为了确定主节点，我们需要知道它的<span class="jill"></span>IP<span class="jill"></span>地址和端口号。主节点还负责监控系统状态、处理任务分配和结果汇总等任务，因此是整个系统的关键部分。</span></li></ul><h3 id="75UGgW25hGJ39v9wHTB9e2" class="wolai-block"><span class="inline-wrap"><b>1.2 通信策略</b></span></h3><div id="Uee2UDYfhzDdezRziLfph" class="wolai-block wolai-text"><div><span class="inline-wrap">deepspeed 还提供了 mpi、gloo 和 nccl 等通信策略，可以根据具体情况进行选择和配置。</span></div></div><ul class="wolai-block"><li id="jzZLiPSjp2y28ndYetWH3g"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>mpi</code></span><span class="inline-wrap">是一种跨节点通信库，常用于 CPU 集群上的分布式训练；</span></li><li id="tHqt4ZooqDpMt9bu8euKow"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>gloo</code></span><span class="inline-wrap"> 是一种高性能的分布式训练框架，支持 CPU 和 GPU 上的分布式训练；</span></li><li id="hSe6gqG4v4L5tKBeeTG5Us"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>nccl</code></span><span class="inline-wrap"> 是 NVIDIA 提供的 GPU 专用通信库，被广泛应用于 GPU 上的分布式训练。</span></li></ul><div id="2ku4pcajYUm6eJoDUtKwY" class="wolai-block wolai-text"><div><span class="inline-wrap">在使用 DeepSpeed 进行分布式训练时，可以根据具体情况选择合适的通信库。通常情况下，如果是在 CPU 集群上进行分布式训练，可以选择 mpi 和 gloo；如果是在 GPU 上进行分布式训练，可以选择 nccl。</span></div></div><code-block id="qKAMxWrsa9E4gL3Tm9scxg" class="wolai-block"><div class="wolai-pre"><div data-lang="Bash" class="marker"></div><pre style="white-space: pre-wrap; word-break: break-all"><span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_LAUNCH_BLOCKING</span><span class="token operator">=</span><span class="token number">1</span></pre></div></code-block><h3 id="gkM4vUCMkbiLsA7TMvCYQV" class="wolai-block"><span class="inline-wrap">1.3 DeepSpeed<span class="jill"></span>训练介绍</span></h3><div id="d2gAHh25BUPYbZtWJk484f" class="wolai-block wolai-text"><div><span class="inline-wrap">在 DeepSpeed 中，可以通过在配置文件中设置 </span><span class="inline-wrap"><code>“bf16.enabled”: true</code></span><span class="inline-wrap"> 来启用 BF16 混合精度训练，减少占用内存。混合精度训练是指在训练过程中同时使用<span class="jill"></span>FP16（半精度浮点数）和<span class="jill"></span>FP32（单精度浮点数）两种精度的技术。</span></div></div><div id="P5ieRugBX3nbH2ocCmePA" class="wolai-block wolai-text"><div><span class="inline-wrap">deepspeed<span class="jill"></span>可以根据具体情况选择合适的通信库，例如在 CPU 集群上进行分布式训练，可以选择 mpi 和 gloo；如果是在 GPU 上进行分布式训练，可以选择 nccl。</span></div></div><div id="8wsKKnKzTqhw1WkwQcERvB" class="wolai-block wolai-text"><div><span class="inline-wrap">DeepSpeed<span class="jill"></span>的核心技术：</span><span class="yellow inline-wrap"><b>Zero</b></span><span class="inline-wrap">（Zero Redundancy Optimizer，3D<span class="jill"></span>优化与卸载）：在<span class="jill"></span>deepspeed<span class="jill"></span>中通过</span><span class="inline-wrap"><code>zero_optimization.stage=0/1/2/3</code></span><span class="inline-wrap"> <span class="jill"></span>设置，卸载通过</span><span class="inline-wrap"><code>zero_optimization.offload_optimizer.device</code></span><span class="inline-wrap">设置</span></div></div><div id="eynVeqtEjiXzFn1PMuu22D" class="wolai-block wolai-text"><div><span class="inline-wrap">DeepSpeed<span class="jill"></span>的推理优化技术：</span></div></div><ul class="wolai-block"><li id="2mSKpierMHpr3BUN1SgZE5"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">Deep fusion：如下图，红色虚线框是以该单位为优化<span class="jill"></span>Kernel，对应的数字是优化的效率倍数</span></li><li id="jprZUEQp1GZCWofYGitdZd"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">Inference-customized GeMM</span></li></ul><div id="ma5CToJ93GP8pZKntHNrTN" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image.png" style="width: 100%"/></figure></div><h2 id="ig5iSNH3R3Cey2NkNUsyHM" class="wolai-block"><span class="inline-wrap"><b>2. Zero（3D<span class="jill"></span>优化与卸载）</b></span></h2><div id="qCYp12ATgGt2oyPyQuaaz8" class="wolai-block wolai-text"><div><span class="inline-wrap">微软开发<span class="jill"></span>ZeRO<span class="jill"></span>是为了克服数据并行性和模型并行性的限制，同时实现两者的优点。</span><span class="yellow inline-wrap"><b>ZeRO<span class="jill"></span>通过在数据并行进程中划分模型状态（参数，梯度和优化器状态），而不是复制它们，从而消除了数据并行进程中的内存冗余。它在训练期间使用动态通信计划，以在分布式设备之间共享必要的状态，以保持计算粒度和数据并行性的通信量</b></span><span class="inline-wrap"><b>。</b></span><span class="inline-wrap"> </span></div></div><div id="3ov7Ej4Un5b5R9j4z6HPeM" class="wolai-block wolai-text"><div><span class="inline-wrap">ZeRO<span class="jill"></span>驱动的数据并行性，它允许每个设备的内存使用量随数据并行性的程度线性扩展，并产生与数据并行性相似的通信量。 ZeRO<span class="jill"></span>支持的数据并行性可以适合任意大小的模型，只要聚合的设备内存足够大以共享模型状态即可。</span></div></div><div id="coPa5xcGqqG1boAKZcQdvy" class="wolai-block wolai-text"><div><span class="inline-wrap">ZeRO（Zero Redundancy Optimizer）是一种用于大规模训练优化的技术，主要是用来减少内存占用。在大规模训练中，内存占用可以分为 Model States 和 Activation 两部分，而 ZeRO 主要是为了解决 Model States 的内存占用问题。</span></div></div><div id="3Yha1pcEuMUSYu8E8HWUCT" class="wolai-block wolai-text"><div><span class="inline-wrap">ZeRO 将模型参数分成了三个部分：Optimizer States、Gradient 和 Model Parameter。</span></div></div><ul class="wolai-block"><li id="6yEY4L2oihSK8AunAN4uGX"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><code>Optimizer States</code></span><span class="inline-wrap"> 是 Optimizer 在进行梯度更新时所需要用到的数据，例如 SGD 中的 Momentum。</span></li><li id="7yxvHeUq4eSLajhYjijGRT"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><code>Gradient </code></span><span class="inline-wrap">是在反向传播后所产生的梯度信息，其决定了参数的更新方向。</span></li><li id="kFUm8rDfd58w3QrfTR8q73"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><code>Model Parameter</code></span><span class="inline-wrap"> 则是模型参数，也就是我们在整个过程中通过数据“学习”的信息。</span></li></ul><div id="dsvKwZzGJmpRnUmc98HLVJ" class="wolai-block wolai-text"><div><span class="inline-wrap">ZeRO-Offload<span class="jill"></span>和<span class="jill"></span>ZeRO-Stage3<span class="jill"></span>是<span class="jill"></span>DeepSpeed<span class="jill"></span>中的不同的<span class="jill"></span>Zero-Redundancy Optimization<span class="jill"></span>技术，用于加速分布式训练，主要区别在资源占用和通信开销方面。</span></div></div><ul class="wolai-block"><li id="iFBKdfnk6ATnvo4aucByR2"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><code>ZeRO-Offload</code></span><span class="inline-wrap">将</span><span class="yellow inline-wrap">模型参数分片到不同的<span class="jill"></span>GPU<span class="jill"></span>上，通过交换节点间通信来降低显存占用，但需要进行额外的通信操作，因此可能会导致训练速度的下降</span><span class="inline-wrap">。</span></li><li id="3AuvLasHxqCByenbESY5Me"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><b><code>ZeRO-Stage3</code></b></span><span class="yellow inline-wrap">将模型参数分布在<span class="jill"></span>CPU<span class="jill"></span>和<span class="jill"></span>GPU<span class="jill"></span>上，通过<span class="jill"></span>CPU<span class="jill"></span>去计算一部分梯度</span><span class="inline-wrap">，从而减少显存占用，但也会带来一定的计算开销。</span></li></ul><h3 id="ibma9eQWXQZhufgQiHNaxG" class="wolai-block"><span class="inline-wrap"><b>2.1 三个级别</b></span></h3><div id="br9xAQTMV7t5DkB3Uhxg6i" class="wolai-block wolai-text"><div><span class="red inline-wrap"><code>ZeRO-0</code></span><span class="inline-wrap">：</span><span class="yellow inline-wrap">禁用所有类型的分片，仅使用 DeepSpeed 作为 DDP</span><span class="inline-wrap"> (Distributed Data Parallel)</span></div></div><div id="piCGpHdqmAJXPibKWQ5KRu" class="wolai-block wolai-text"><div><span class="red inline-wrap"><code>ZeRO-1</code></span><span class="inline-wrap">：</span><span class="yellow inline-wrap">分割<span class="jill"></span>Optimizer States，减少了<span class="jill"></span>4<span class="jill"></span>倍的内存</span><span class="inline-wrap">，通信容量与数据并行性相同</span></div></div><div id="eieTdWpm7FLEtpXQ2wKg6r" class="wolai-block wolai-text"><div><span class="red inline-wrap"><code>ZeRO-2</code></span><span class="inline-wrap">：</span><span class="yellow inline-wrap">分割<span class="jill"></span>Optimizer States<span class="jill"></span>与<span class="jill"></span>Gradients，8x<span class="jill"></span>内存减少</span><span class="inline-wrap">，通信容量与数据并行性相同</span></div></div><div id="ocPuymTwjNSgzc8NdiEWsb" class="wolai-block wolai-text"><div><span class="red inline-wrap"><code>ZeRO-3</code></span><span class="inline-wrap">：</span><span class="yellow inline-wrap">分割<span class="jill"></span>Optimizer States、Gradients<span class="jill"></span>与<span class="jill"></span>Parameters</span><span class="inline-wrap">，内存减少与数据并行度和复杂度成线性关系。</span></div></div><div id="eswchMcRttW3s7Bkuxbs8r" class="wolai-block wolai-text"><div><span class="red inline-wrap"><code>ZeRO-Infinity</code></span><span class="inline-wrap">是<span class="jill"></span>ZeRO-3<span class="jill"></span>的拓展。允许通过使用 NVMe 固态硬盘扩展 GPU 和 CPU 内存来训练大型模型。ZeRO-Infinity 需要启用 ZeRO-3。</span></div></div><div id="6uiHbLnw6W68t9JdNi79C7" class="wolai-block wolai-text"><div><span class="inline-wrap">在<span class="jill"></span>deepspeed<span class="jill"></span>中通过<span class="jill"></span>zero_optimization.stage=0/1/2/3 设置，</span></div></div><div id="rLFih5oG6gTZtnmp9PGGLn" class="wolai-block wolai-text"><div><span class="inline-wrap">卸载通过<span class="jill"></span>zero\_optimization.offload\_optimizer.device<span class="jill"></span>设置</span></div></div><h3 id="nRaQAqFr6UNLx69aKemfpW" class="wolai-block"><span class="inline-wrap"><b>2.2 混合精度</b></span></h3><div id="irTnPWRg4JAs8oMwjGFBME" class="wolai-block wolai-text"><div><span class="inline-wrap">混合精度训练是指在训练过程中同时使用<span class="jill"></span>FP16（半精度浮点数）和<span class="jill"></span>FP32（单精度浮点数）两种精度的技术。</span><span class="yellow inline-wrap"><b>使用<span class="jill"></span>FP16<span class="jill"></span>可以大大减少内存占用，从而可以训练更大规模的模型</b></span><span class="inline-wrap">。但是，</span><span class="yellow inline-wrap"><b>由于<span class="jill"></span>FP16<span class="jill"></span>的精度较低，训练过程中可能会出现梯度消失和模型不稳定的问题</b></span><span class="inline-wrap">。因此，需要使用一些技术来解决这些问题，例如</span><span class="red inline-wrap"><b>动态精度缩放（Dynamic Loss Scaling）</b></span><span class="inline-wrap">和</span><span class="red inline-wrap"><b>混合精度优化器（Mixed Precision Optimizer）</b></span><span class="inline-wrap">等。</span></div></div><div id="2oYeRgquvNa2GRbKK8bAjU" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_1.png" style="width: 661px"/></figure></div><div id="cP6wrknSSQbGVMhuWhHesJ" class="wolai-block wolai-text"><div><span class="inline-wrap">deepspeed<span class="jill"></span>提供了混合精度训练的支持，可以通过在配置文件中设置</span><span class="inline-wrap"><code>&quot;fp16.enabled&quot;: true</code></span><span class="inline-wrap">来启用混合精度训练。在训练过程中，</span><span class="red inline-wrap">deepspeed<span class="jill"></span>会自动将一部分操作转换为<span class="jill"></span>FP16<span class="jill"></span>格式，并根据需要动态调整精度缩放因子，从而保证训练的稳定性和精度</span><span class="inline-wrap">。</span></div></div><div id="sBUux13REXW6PmG1ecMWmF" class="wolai-block wolai-text"><div><span class="inline-wrap">在使用混合精度训练时，需要注意一些问题，例如</span><span class="yellow inline-wrap">梯度裁剪（Gradient Clipping）</span><span class="inline-wrap">和</span><span class="yellow inline-wrap">学习率调整（Learning Rate Schedule）</span><span class="inline-wrap">等。</span><span class="red inline-wrap">梯度裁剪可以防止梯度爆炸，学习率调整可以帮助模型更好地收敛</span><span class="inline-wrap">。因此，在设置混合精度训练时，需要根据具体情况进行选择和配置。</span></div></div><div id="9Ta2dAha2B8wjqgk1o4Rwh" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_2.png" style="width: 100%"/></figure></div><div id="rsyecbAkRVqz5EJLdhVzpF" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>BF16</b></span></div></div><div id="e7uKg87N7tQRq284ie9WJx" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>BF16<span class="jill"></span>和<span class="jill"></span>FP16<span class="jill"></span>都是混合精度训练中使用的浮点数表示格式</b></span><span class="inline-wrap">。</span></div></div><div id="ckkb41JpG8UyLfSnqrwwYD" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_3.png" style="width: 657px"/></figure></div><div id="xA3o7A3YqtDxZEyiKxFU6j" class="wolai-block wolai-text"><div><span class="inline-wrap">BF16<span class="jill"></span>是一种<span class="jill"></span>Brain Floating Point<span class="jill"></span>格式，由英特尔提出，可以提供更好的数值稳定性和更高的精度，但需要更多的存储空间。在混合精度训练中，</span><span class="red inline-wrap"><b>BF16<span class="jill"></span>可以作为一种精度更高的替代品，用于一些关键的计算操作，例如梯度累加和权重更新等</b></span><span class="inline-wrap">。使用<span class="jill"></span>BF16<span class="jill"></span>可以提高模型的训练速度和精度，并减少内存占用。</span></div></div><div id="6rWqVfeNcZnkacqfd62emA" class="wolai-block wolai-text"><div><span class="inline-wrap">在 DeepSpeed 中，可以通过在配置文件中设置 </span><span class="inline-wrap"><code>&quot;bf16.enabled&quot;: true</code></span><span class="inline-wrap"> 来启用 BF16 混合精度训练。这将会将一部分操作转换为 BF16 格式，并根据需要动态调整精度缩放因子，从而提高模型的训练速度和精度，并减少内存占用。</span></div></div><div id="4ECXRseEG5DCxi2oxcfA97" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>NVIDIA Tesla V100 不支持<span class="jill"></span>BF16</b></span></div></div><h3 id="9yPmGUpQzDBWPZXybGUHhX" class="wolai-block"><span class="inline-wrap"><b>2.3 显存占用分析</b></span></h3><div id="pjvwJVx4v2RUYbDMoVZ1kW" class="wolai-block wolai-text"><div><span class="inline-wrap">混合精度训练，字如其名，同时存在<span class="jill"></span>fp16<span class="jill"></span>和<span class="jill"></span>fp32<span class="jill"></span>两种格式的数值，其中模型参数、模型梯度都是<span class="jill"></span>fp16，此外还有<span class="jill"></span>fp32<span class="jill"></span>的模型参数，如果优化器是<span class="jill"></span>Adam，则还有<span class="jill"></span>fp32<span class="jill"></span>的<span class="jill"></span>momentum<span class="jill"></span>和<span class="jill"></span>variance。</span></div></div><div id="njkqM4bb6FCpewLoEYpzmV" class="wolai-block wolai-text"><div><span class="inline-wrap">总的来说，模型训练时显存主要分为两部分。</span></div></div><ul class="wolai-block"><li id="stFzhC5ihQUwGZmrJ3FiLq"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><b>第一部分</b></span><span class="inline-wrap">是</span><span class="red inline-wrap">模型权重、梯度和优化器状态</span><span class="inline-wrap">；</span></li><li id="bBi2KdXCCYccSPBwm7hNHc"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><b>第二部分</b></span><span class="inline-wrap">是</span><span class="red inline-wrap">激活和临时缓存区</span><span class="inline-wrap">。</span></li></ul><div id="ex2L4EXiJRz4Bs27qLunzF" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>ZeRO-DP<span class="jill"></span>主要是优化第一部分的显存占用，所以这里主要介绍第一部分的显存。</b></span><span class="inline-wrap"> </span></div></div><div id="vMyrtuhZNiV9XpbhjGkhae" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_4.png" style="width: 100%"/></figure></div><div id="7VL6LYDdp9pREvLdMJH1D" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_5.png" style="width: 100%"/></figure></div><ul class="wolai-block"><li id="ni7aFn55BH8UchFNcdr7RQ"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><b>将权重转换为<span class="jill"></span>FP16</b></span><span class="inline-wrap">：在这一步中，神经网络的权重（或参数）最初是<span class="jill"></span>FP32<span class="jill"></span>格式，被转换为低精度的<span class="jill"></span>FP16<span class="jill"></span>格式。这减少了内存的占用，并允许更快的计算，因为<span class="jill"></span>FP16<span class="jill"></span>操作需要更少的内存，并且可以被硬件更快地处理。  </span></li><li id="wvXqMXSb3fREJGMz6Boiz8"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><b>计算梯度</b></span><span class="inline-wrap">：神经网络的前向和后向通道是使用较低精度的<span class="jill"></span>FP16<span class="jill"></span>权重进行的。这一步计算损失函数相对于网络权重的梯度（部分导数），在优化过程中用于更新权重。</span></li><li id="tNQ13hjBrLLMM7HpE55AuQ"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><b>将梯度转换为<span class="jill"></span>FP32</b></span><span class="inline-wrap">：在<span class="jill"></span>FP16<span class="jill"></span>中计算梯度后，它们被转换回高精度的<span class="jill"></span>FP32<span class="jill"></span>格式。这种转换对于保持数值稳定性和避免使用低精度算术时可能出现的梯度消失或爆炸等问题至关重要。  </span></li><li id="oUH3TYv9KSaWbsFjy9AmYi"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="red inline-wrap"><b>乘以学习率和更新权重</b></span><span class="inline-wrap">：现在是<span class="jill"></span>FP32<span class="jill"></span>格式，梯度被乘以学习率（一个标量值，决定了优化过程中的步长）。乘积被用来更新原始<span class="jill"></span>FP32<span class="jill"></span>神经网络权重。学习率有助于控制优化过程的收敛性，对于实现良好的性能至关重要。</span></li></ul><h4 id="4F6ByGG7GqFNJRa4meszB9" class="wolai-block"><span class="inline-wrap">（1）</span><span class="inline-wrap"><b>模型状态</b></span><span class="inline-wrap">（model states）</span></h4><div id="cLGWLzzZu12HnWUCBnvsTg" class="wolai-block wolai-text"><div><span class="inline-wrap">假设模型的参数量是<span class="jill"></span> </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">Ψ</span></span></span></span></span><span class="inline-wrap"> ，使用<span class="jill"></span>Adam<span class="jill"></span>为优化器进行混合精度训练。</span></div></div><ol class="wolai-block"><li id="6MU7TsFDjYRtUqGhPnhbtV"><div class="marker"></div><span class="inline-wrap">由于模型的参数和梯度使用<span class="jill"></span>float16，所以显存消耗分别为<span class="jill"></span> </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">2Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Ψ</span></span></span></span></span><span class="inline-wrap"> <span class="jill"></span>和<span class="jill"></span> </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">2Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Ψ</span></span></span></span></span><span class="inline-wrap"> 。</span></li><li id="3mBw723hjuVS4LBsR2LqXK"><div class="marker"></div><span class="inline-wrap">Adam<span class="jill"></span>会维护一个<span class="jill"></span>float32<span class="jill"></span>的模型备份副本，消耗 </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">4Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span></span></span></span></span><span class="inline-wrap"> 显存。Adam<span class="jill"></span>优化器本身会为模型的每个参数维护两个<span class="jill"></span>float32<span class="jill"></span>的辅助变量（fp32<span class="jill"></span>的<span class="jill"></span>momentum<span class="jill"></span>和<span class="jill"></span>fp32<span class="jill"></span>的<span class="jill"></span>variance），所以显存消耗占用为 </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">4Ψ+4Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span></span></span></span></span><span class="inline-wrap"> 。</span></li></ol><div id="fBi1YhpLUCS8r1QTAKbha1" class="wolai-block wolai-text"><div><span class="inline-wrap">总的来说，模型会消耗<span class="jill"></span> </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>2</mn><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">2Ψ+2Ψ=4Ψ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">2Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">2Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span></span></span></span></span><span class="inline-wrap"> ，Adam<span class="jill"></span>优化器这消耗</span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext> </mtext><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>12</mn><mi mathvariant="normal">Ψ</mi><mtext> </mtext></mrow><annotation encoding="application/x-tex"> 4Ψ+4Ψ+4Ψ=12Ψ </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord"> 4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">12Ψ </span></span></span></span></span><span class="inline-wrap">。最终的总消耗为<span class="jill"></span> </span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mn>12</mn><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>16</mn><mi mathvariant="normal">Ψ</mi><mtext> </mtext></mrow><annotation encoding="application/x-tex">4Ψ+12Ψ=16Ψ </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">12Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">16Ψ </span></span></span></span></span><span class="inline-wrap">。</span></div></div><div id="kMdoGmYQEM59qrVDt73XUY" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_6.png" style="width: 100%"/></figure></div><div id="3Q1u2nvtkbAdwQQ6fFpJ6r" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>这里为了方便讨论，将优化器显存占用表示为<span class="jill"></span> </b></span><span class="red"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">KΨ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">Ψ</span></span></span></span></span><span class="red inline-wrap"><b> (不同的优化器不同)，则混合精度训练的显存占用为<span class="jill"></span> </b></span><span class="red"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi mathvariant="normal">Ψ</mi><mo>+</mo><mi>K</mi><mi mathvariant="normal">Ψ</mi></mrow><annotation encoding="application/x-tex">4Ψ+KΨ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord">4Ψ</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">Ψ</span></span></span></span></span><span class="red inline-wrap"><b> 。 </b></span></div></div><div id="gH9pABf8TkMx8fsofFjdzA" class="wolai-block wolai-text"><div><span class="inline-wrap">来看一个例子，</span><span class="red inline-wrap"><b>GPT-2</b></span><span class="inline-wrap">含有<span class="jill"></span>1.5B<span class="jill"></span>个参数，如果用<span class="jill"></span>fp16<span class="jill"></span>格式，只需要</span><span class="red inline-wrap"><code>1.5G*2Byte=3GB</code></span><span class="inline-wrap">显存</span></div></div><div id="fy7K1JSWrMzzhagJT1KYxA" class="wolai-block wolai-text"><div><span class="inline-wrap">但是模型状态实际上需要耗费</span><span class="inline-wrap"><code>1.5*16=24GB</code></span><span class="inline-wrap">, 相比之下，激活值可以用</span><span class="inline-wrap"><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1604.06174.pdf"><span>activation checkpointing</span></a></span><span class="inline-wrap">来大大减少，所以模型状态就成了头号显存杀手，它也是<span class="jill"></span>ZeRO<span class="jill"></span>的重点优化对象。而其中<span class="jill"></span>Adam<span class="jill"></span>状态又是第一个要被优化的。</span></div></div><div id="ctsw2f3r1GYvzcKKNTYbHF" class="wolai-block wolai-text"><div><span class="inline-wrap">比如说有一个模型参数量是<span class="jill"></span>1M，在一般的深度学习框架中(比如说<span class="jill"></span>PyTorch)，一般是<span class="jill"></span>32<span class="jill"></span>位存储。32<span class="jill"></span>位存储的意思就是<span class="jill"></span>1<span class="jill"></span>个参数用<span class="jill"></span>32<span class="jill"></span>个<span class="jill"></span>bit<span class="jill"></span>来存储。那么这个拥有<span class="jill"></span>1M<span class="jill"></span>参数量的模型所需要的存储空间的大小即为：1M * 32 bit = 32Mb = 4MB。因为<span class="jill"></span>1 Byte = 8 bit。现在的<span class="jill"></span>quantization<span class="jill"></span>技术就是减少参数量所占的位数：比如我用<span class="jill"></span>16<span class="jill"></span>位存储，那么：所需要的存储空间的大小即为：1M * 16 bit = 16Mb = 2MB。</span></div></div><h4 id="rMhdp7EpX6w3jQtnw6pPog" class="wolai-block"><span class="inline-wrap"><b>（2）剩余状态</b></span><span class="inline-wrap">（residual states）</span></h4><div id="vVGeV9WDKBzZC8iEJnNQRj" class="wolai-block wolai-text"><div><span class="inline-wrap"> 除了模型状态之外的显存占用，包括</span><span class="red inline-wrap"><b>激活值（activation）、各种临时缓冲区（buffer）以及无法使用的显存碎片（fragmentation）</b></span><span class="inline-wrap">。</span></div></div><div id="kS9XXGWktbVRTU2UZoEZgF" class="wolai-block wolai-text"><div><span class="inline-wrap">显然，激活在训练中也会消耗大量的显存。一个具体的例子，模型为<span class="jill"></span>1.5B<span class="jill"></span>的<span class="jill"></span>GPT-2，序列长度为<span class="jill"></span>1K，batch size<span class="jill"></span>为<span class="jill"></span>32，则消耗显存为<span class="jill"></span>60GB。Activation checkpointing(或者<span class="jill"></span>activation recomputation)则是一种常见的降低激活占用显存的方法。该方法以<span class="jill"></span>33%<span class="jill"></span>的重计算为代价，将激活的显存占用减少至总激活的均分更。即激活显存占用从<span class="jill"></span>60GB<span class="jill"></span>降低至<span class="jill"></span>8GB。</span></div></div><div id="iGwEhB4ysHU2WF2pQEzaQM" class="wolai-block wolai-text"><div><span class="inline-wrap">尽管激活的显存占用已经显著减少，但是对于更大的模型来说，激活所占用的显存也会非常大。例如，对于<span class="jill"></span>100B<span class="jill"></span>参数量的<span class="jill"></span>GPT<span class="jill"></span>模型且<span class="jill"></span>batch size<span class="jill"></span>为<span class="jill"></span>32，即使用来<span class="jill"></span>activation checkpointing，显存占用也需要<span class="jill"></span>60GB。</span></div></div><div id="ofBEqn2Ag2xWTd31WGdrR9" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>临时缓存区(Temporary buffers)</b></span><span class="inline-wrap">。对于大模型，用于存储中间结果的临时<span class="jill"></span>buffer<span class="jill"></span>也会消耗大量显存。例如在<span class="jill"></span>all-reduce<span class="jill"></span>时，需要一个平坦的<span class="jill"></span>buffer<span class="jill"></span>来融合所有的梯度，从而改善吞吐量。例如，跨设备的<span class="jill"></span>all-reduce<span class="jill"></span>操作会随着消息的增大而增加。虽然，梯度本文是<span class="jill"></span>fp16<span class="jill"></span>的张量，但是有些操作中可能需要融合的<span class="jill"></span>buffer<span class="jill"></span>为<span class="jill"></span>fp32。当模型尺寸很大时，临时的<span class="jill"></span>buffer<span class="jill"></span>也不小。例如，对于<span class="jill"></span>1.5B<span class="jill"></span>参数的模型，一个<span class="jill"></span>fp32<span class="jill"></span>的<span class="jill"></span>buffer<span class="jill"></span>需要<span class="jill"></span>6GB<span class="jill"></span>的显存。</span></div></div><div id="5p6pU2jLiLWe6wbMPULmVi" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>显存碎片</b></span><span class="inline-wrap">。即使在有足够显存的情况下，也可能会导致<span class="jill"></span>Out of Memory，这是由于显存碎片导致的。在进程发出显存请求时，如果没有连续的显存来满足请求，即使总的显存仍然足够，该请求也会失败。当训练非常大的模型时，可以观察到明显的显存碎片。极端情况下，可能会导致<span class="jill"></span>30%<span class="jill"></span>的显存碎片。</span></div></div><h2 id="wn52LhpJchJA4zaajvHGF2" class="wolai-block"><span class="inline-wrap"><b>3.ZeRO-DP</b></span></h2><div id="ejBtG6aQpUUQkTQz1PjXua" class="wolai-block wolai-text"><div><span class="inline-wrap">ZeRO-DP(Zero Redundancy Optimizer-Data Parallelism)是来自于论文《ZeRO: Memory Optimizations Toward Training Trillion Parameter Models》中的一种显存优化方法<span class="jill"></span>ZeRO<span class="jill"></span>的核心部分。通过该方法可以大幅度的优化显存占用，</span><span class="red inline-wrap"><b>从而在有限的资源下训练更大的模型</b></span><span class="inline-wrap">。</span></div></div><div id="xh86t2FzUqiHedUXiJjjcR" class="wolai-block wolai-text"><div><span class="inline-wrap">针对模型状态的存储优化（去除冗余），</span><span class="red inline-wrap">ZeRO<span class="jill"></span>使用的方法是分片（partition）</span><span class="inline-wrap">，即</span><span class="yellow inline-wrap">每张卡只存<span class="jill"></span> 1/N<span class="jill"></span>的模型状态量，这样系统内只维护一份模型状态</span><span class="inline-wrap">。</span></div></div><div id="nQ7KvzrVHPj6XQVjE73wVa" class="wolai-block wolai-text"><div><span class="inline-wrap">这里<span class="jill"></span>os<span class="jill"></span>指的是<span class="jill"></span>optimizer</span></div></div><div id="77WYEiKjcsDpgSUxtJGEsY" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_7.png" style="width: 100%"/></figure></div><div id="kHG3F2D8oGhutxGaQjfwtt" class="wolai-block wolai-text"><div><span class="inline-wrap">看上去比较高大上，可能让你很难专心去理解，但实际上，这个概念非常简单。这只是通常的 DDP，只是没有每个 GPU 都复制完整的模型参数、梯度和优化器状态，而是每个 GPU 只存储其中的一部分。在随后的运行过程中，当需要给定层的完整层参数时，所有 GPU 同步以相互提供它们缺失的部分 —— 仅此而已。</span></div></div><div id="fABxffjEGqjcFvtjCSA3Fv" class="wolai-block wolai-text"><div><span class="inline-wrap">第二列给出了一个示例：</span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>=</mo><mn>12</mn><mo separator="true">,</mo><mi mathvariant="normal">Ψ</mi><mo>=</mo><mn>7.5</mn><mi>B</mi><mo separator="true">,</mo><mi>N</mi><mo>=</mo><mn>64</mn><mtext> </mtext></mrow><annotation encoding="application/x-tex"> K=12,Ψ=7.5B,N=64 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord">12</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">Ψ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em;"></span><span class="mord">7.5</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">64 </span></span></span></span></span><span class="inline-wrap">可以看到显存优化相当明显。</span></div></div><div id="kQcsJGVKvH3Moyeb3L8yxC" class="wolai-block wolai-text"><div><span class="inline-wrap">在标准的数据并行中，每个显卡(rank)都会保存独立的</span><span class="inline-wrap"><b>权重、梯度和优化器状态</b></span><span class="inline-wrap">，如上图中的<span class="jill"></span>baseline<span class="jill"></span>所示。那么每个显卡是否有必要存储全部的这些信息呢？</span><span class="inline-wrap"><b>ZeRO-DP<span class="jill"></span>的答案是不需要</b></span><span class="inline-wrap">。ZeRO-DP<span class="jill"></span>能够对模型状态(权重、梯度和优化器状态)进行划分(不像标准<span class="jill"></span>DP<span class="jill"></span>那样进行复制)，然后通过动态通信调度来最小化通信开销。ZeRO-DP<span class="jill"></span>能够在保持整体通信开销接近标准<span class="jill"></span>DP<span class="jill"></span>的同时，线性地降低模型的</span><span class="inline-wrap"><b>单显卡</b></span><span class="inline-wrap">显存占用。</span></div></div><h3 id="un9yecSH9d1NotAxnsJBw4" class="wolai-block"><span class="inline-wrap"><b>3.1 ZeRO-DP<span class="jill"></span>的细节</b></span></h3><div id="aDnJWFn56Y7SMNpya45UnN" class="wolai-block wolai-text"><div><span class="inline-wrap">总的来说，ZeRO-DP<span class="jill"></span>可以分为三个阶段：</span><span class="yellow inline-wrap"><b>Pos, Pg, Pp</b></span><span class="inline-wrap"> 。三个阶段对应优化器状态划分、梯度划分和模型参数划分，并且三个阶段可以叠加使用(上图展示了三个阶段的叠加)。关于三个阶段是否会增加通信量，会在后面分析，目前先接受这三个阶段并不会显著增加通信开销。</span></div></div><div id="8P6k6mBxKRT6ZHZJsFafjn" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_8.png" style="width: 100%"/></figure></div><div id="onmkCqhGitJCkZyA3iRzSv" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_9.png" style="width: 100%"/></figure></div><div id="btWs6vK6KPnZH2HM2W3ALx" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_10.png" style="width: 100%"/></figure></div><div id="juwGa3T26ZmVCMw3G9Hsu9" class="wolai-block wolai-text"><div><span class="inline-wrap">在<span class="jill"></span>DeepSpeed<span class="jill"></span>中，一般使用<span class="jill"></span>ZeRO-1<span class="jill"></span>就足够了。</span></div></div><div id="4RGRnGynHnDruQrJ7zDzLZ" class="wolai-block"><figure class="wolai-center" style="width: 100%"><img src="media/image_11.png" style="width: 100%"/></figure></div><h3 id="aYnE1aVFw5tBqceWmXMQ6K" class="wolai-block"><span class="inline-wrap">3.2 </span><span class="inline-wrap"><b>ZeRO-DP<span class="jill"></span>通信量</b></span></h3><div id="wuuG2Lq5joCLRxa3DKMJb8" class="wolai-block wolai-text"><div><span class="inline-wrap">ZeRO<span class="jill"></span>通过去除显存的冗余来提升模型尺寸，那么该方法是否是通过通信量换取的显存效率。换句话说，ZeRO-DP<span class="jill"></span>相较于标准<span class="jill"></span>DP<span class="jill"></span>来说，通信量增大了吗？</span></div></div><div id="buPVCx2vcSLxiczgRPw5sY" class="wolai-block wolai-text"><div><span class="inline-wrap">答案分为两部分：</span></div></div><ol class="wolai-block"><li id="6KszQsEHgAEedykzRk7Ece"><div class="marker"></div><span class="yellow inline-wrap"><b>ZeRO-DP<span class="jill"></span>在使用</b></span><span class="yellow inline-wrap"> Pos </span><span class="yellow inline-wrap"><b>和</b></span><span class="yellow inline-wrap"> Pg</span><span class="yellow inline-wrap"><b>的情况下，能够带来<span class="jill"></span>8<span class="jill"></span>倍的显存降低且不增加额外的通信量</b></span><span class="inline-wrap"><b>；</b></span></li><li id="73JyeYbsExCQCpnVPQkcW2"><div class="marker"></div><span class="yellow inline-wrap"><b>当同时使用</b></span><span class="yellow inline-wrap"> Pos </span><span class="yellow inline-wrap"><b>、</b></span><span class="yellow inline-wrap"> Pg </span><span class="yellow inline-wrap"><b>和</b></span><span class="yellow inline-wrap">Pp</span><span class="yellow inline-wrap"><b>时，通信量增加<span class="jill"></span>1.5<span class="jill"></span>倍，同时降低倍的显存</b></span><span class="inline-wrap"><b>。</b></span><span class="inline-wrap"> </span></li></ol><div id="3L7pVC9ZZWoYMcjMAepRv5" class="wolai-block wolai-text"><div><span class="inline-wrap">在分析之前，我们先回顾下常用的集合通信（collective communication）函数</span><span class="inline-wrap"><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/collectives.html"><span>Collective Operations</span></a></span><span class="inline-wrap">。</span></div></div><h4 id="9usaLf9acdRsrssLqd5kwJ" class="wolai-block"><span class="inline-wrap"><b>（1）标准数据并行的通信量</b></span></h4><div id="bLCukcmUUS1qADQee8Z8di" class="wolai-block wolai-text"><div><span class="inline-wrap">在标准的数据并行训练中，在反向传播结束后，跨显卡的梯度会被平均。这个平均的过程使用<span class="jill"></span>all-reduce。对于大尺寸的模型，all-reduce<span class="jill"></span>通信是整个通信带宽的上界，因此分析主要集中在<span class="jill"></span>all-reduce<span class="jill"></span>上。</span></div></div><div id="88CYhRBzvYw7kvyovwXFfU" class="wolai-block wolai-text"><div><span class="inline-wrap">传统数据数据并行在每一步（step/iteration）计算梯度后，需要进行一次<span class="jill"></span>AllReduce<span class="jill"></span>操作来计算梯度均值，目前常用的是<span class="jill"></span>Ring AllReduce，分为<span class="jill"></span>ReduceScatter<span class="jill"></span>和<span class="jill"></span>AllGather<span class="jill"></span>两步，每张卡的通信数据量（发送<span class="jill"></span>+<span class="jill"></span>接受）。总的来说，单个显卡在<span class="jill"></span>reduce-scatter<span class="jill"></span>或者<span class="jill"></span>all-gather<span class="jill"></span>的过程中，都会有<span class="jill"></span> Ψ <span class="jill"></span>的通信量。那么，整个<span class="jill"></span>all-reduce<span class="jill"></span>的单显卡通信量为<span class="jill"></span> 2Ψ 。</span></div></div><div id="urQRyWDwdxVo8xqWwaFkJ7" class="wolai-block wolai-text"><div><span class="inline-wrap">参考：</span><span class="inline-wrap"><a target="_blank" rel="noopener" href="https://zengwenqi.blog.csdn.net/article/details/130501965"><span>[深度学习]Ring All-reduce<span class="jill"></span>的数学性质-CSDN<span class="jill"></span>博客</span></a></span></div></div><h4 id="mPdZYebybL7EFCPqXrq1pm" class="wolai-block"><span class="inline-wrap"><b>（2）Zero-DP<span class="jill"></span>的通信量</b></span></h4><div id="2RaJMDrXQxLtzcvASNKCZd" class="wolai-block wolai-text"><div><span class="inline-wrap">Pos</span><span class="inline-wrap"><b>的通信量</b></span></div></div><div id="gLpiXzo3QJrEuMZqVWTJKH" class="wolai-block wolai-text"><div><span class="inline-wrap">在单独使用 Pos<span class="jill"></span>的情况下，单个显卡会保存完整的模型参数和梯度。随后使用<span class="jill"></span>reduce-scatter<span class="jill"></span>将梯度<span class="jill"></span>reduce<span class="jill"></span>至不同的显卡上(</span><span class="inline-wrap"><b>此时不同显卡仅拥有完整平均梯度的一部分</b></span><span class="inline-wrap">)，该步骤的通信量是<span class="jill"></span> Ψ 。各个显卡使用部分梯度更新对应的优化器状态，然后再更新对应的参数(</span><span class="inline-wrap"><b>此时每个显卡上的模型都更新了一部分参数</b></span><span class="inline-wrap">)。最后，使用<span class="jill"></span>all-gather<span class="jill"></span>将分布在各个显卡上的更新后参数分发自所有显卡上(</span><span class="inline-wrap"><b>此时所有显卡上都有了完整的更新后参数</b></span><span class="inline-wrap">)，该步骤的通信量是<span class="jill"></span> Ψ 。总的来说，各个显卡仅需要持有部分优化器状态即可，且总的通信量仍然是<span class="jill"></span> 2Ψ 。</span></div></div><h2 id="3Azr3FC9QLm4f6vMRmy7NN" class="wolai-block"><span class="inline-wrap"><b>4.DeepSpeed<span class="jill"></span>训练</b></span></h2><h3 id="dPF832kDUoMsnrUA6SCgoU" class="wolai-block"><span class="inline-wrap">4.1 基本训练的介绍</span></h3><div id="ELMUdwzkdPpJv6f1TtnoT" class="wolai-block wolai-text"><div><span class="inline-wrap">安装 DeepSpeed：</span></div></div><code-block id="mCUwedXtVj52MHd5ic75aG" class="wolai-block"><div class="wolai-pre"><div data-lang="Bash" class="marker"></div><pre>pip <span class="token function">install</span> deepspeed
</pre></div></code-block><ol class="wolai-block"><li id="uwR9oJ7ziKSvQRNNsukVk"><div class="marker"></div><span class="inline-wrap">在训练脚本中导入 DeepSpeed 模块：</span></li><li id="awd339WkrHjSjkBL8rUb3Z"><div class="marker"></div><span class="inline-wrap">在训练脚本中导入 Trainer 模块：</span></li><li id="7eGeixBZXWCv6jbbtLyn7R"><div class="marker"></div><span class="inline-wrap">创建 Trainer 对象，将模型、训练数据集、优化器等参数传入：</span></li></ol><code-block id="awMVyEK9huJzr2zMxZaxwA" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token keyword">import</span> deepspeed
 
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Trainer
 
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>train_dataset<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>data_collator<span class="token punctuation">,</span>
    optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></div></code-block><ol class="wolai-block"><li id="78MqQkdam7ctkRYTAVTPMs"><div class="marker"></div><span class="inline-wrap">使用 DeepSpeed 命令行工具运行训练脚本（单机）：</span></li></ol><code-block id="txNC5m8CuFiSkoPC4sT2n6" class="wolai-block"><div class="wolai-pre"><div data-lang="Bash" class="marker"></div><pre>deepspeed <span class="token parameter variable">--num_gpus</span><span class="token operator">=</span><span class="token number">8</span> train.py
</pre></div></code-block><div id="9ym6USGQSiuthwfj5bSpnH" class="wolai-block wolai-text"><div><span class="inline-wrap">其中，</span><span class="inline-wrap"><code>--num_gpus</code></span><span class="inline-wrap"> <span class="jill"></span>表示使用的 GPU 数量。</span></div></div><div id="vJVWTYvQtzeqc3QGxCgTDw" class="wolai-block wolai-text"><div><span class="inline-wrap">多节点：</span></div></div><code-block id="dExji7rsWzAg6aotoLKq5S" class="wolai-block"><div class="wolai-pre"><div data-lang="Bash" class="marker"></div><pre>deepspeed  <span class="token parameter variable">--hostfile</span><span class="token operator">=</span>hostfile  <span class="token parameter variable">--master_port</span> <span class="token number">60000</span> <span class="token parameter variable">--include</span><span class="token operator">=</span><span class="token string">"node1:0,1,2,3@node2:0,1,2,3"</span> run.py <span class="token punctuation">\</span>
<span class="token parameter variable">--deepspeed</span> ds_config.json</pre></div></code-block><div id="mg8Gw7vkeAxs9BmdMEerwb" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>hostfile</b></span></div></div><div id="9HxaNzwRYRkLFidcjEPqV4" class="wolai-block wolai-text"><div><span class="inline-wrap">增加<span class="jill"></span>hostfile<span class="jill"></span>文件，填写<span class="jill"></span>host<span class="jill"></span>的相应的<span class="jill"></span>gpu<span class="jill"></span>数量(slots=4<span class="jill"></span>代表有<span class="jill"></span>4<span class="jill"></span>个<span class="jill"></span>gpu)</span></div></div><code-block id="rjbNPeJbB86z5Mhoc43YCJ" class="wolai-block"><div class="wolai-pre"><div data-lang="Bash" class="marker"></div><pre style="white-space: pre-wrap; word-break: break-all">node1_ip <span class="token assign-left variable">slots</span><span class="token operator">=</span><span class="token number">4</span>
node2_ip <span class="token assign-left variable">slots</span><span class="token operator">=</span><span class="token number">4</span></pre></div></code-block><div id="tVVZMWhQvwrZC5CFucftvq" class="wolai-block wolai-text"><div><span class="inline-wrap">include<span class="jill"></span>参数，指定机器和<span class="jill"></span>gpu,如下代表使用<span class="jill"></span>host1<span class="jill"></span>机器的<span class="jill"></span>3<span class="jill"></span>号和<span class="jill"></span>host2<span class="jill"></span>的<span class="jill"></span>2、3<span class="jill"></span>号<span class="jill"></span>gpu</span></div></div><div id="mzXvN5VFgpcs5uGqYqiq7X" class="wolai-block wolai-text"><div><span class="inline-wrap"><b>ds_config.json</b></span></div></div><code-block id="fDyzkHCrKmey9qSL3FTtb4" class="wolai-block"><div class="wolai-pre"><div data-lang="JSON" class="marker"></div><pre><span class="token punctuation">&#123;</span>
    <span class="token property">"fp16"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
        <span class="token property">"enabled"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
        <span class="token property">"loss_scale"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token property">"loss_scale_window"</span><span class="token operator">:</span> <span class="token number">1000</span><span class="token punctuation">,</span>
        <span class="token property">"initial_scale_power"</span><span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>
        <span class="token property">"hysteresis"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
        <span class="token property">"min_loss_scale"</span><span class="token operator">:</span> <span class="token number">1</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
 
    <span class="token property">"optimizer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
        <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"AdamW"</span><span class="token punctuation">,</span>
        <span class="token property">"params"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"lr"</span><span class="token operator">:</span> <span class="token number">3e-5</span><span class="token punctuation">,</span>
            <span class="token property">"betas"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.999</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token property">"eps"</span><span class="token operator">:</span> <span class="token number">1e-8</span><span class="token punctuation">,</span>
            <span class="token property">"weight_decay"</span><span class="token operator">:</span> <span class="token number">3e-7</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
 
    <span class="token property">"scheduler"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
        <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"WarmupLR"</span><span class="token punctuation">,</span>
        <span class="token property">"params"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"warmup_min_lr"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
            <span class="token property">"warmup_max_lr"</span><span class="token operator">:</span> <span class="token number">3e-5</span><span class="token punctuation">,</span>
            <span class="token property">"warmup_num_steps"</span><span class="token operator">:</span> <span class="token number">500</span>
        <span class="token punctuation">&#125;</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
 
    <span class="token property">"zero_optimization"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
        <span class="token property">"stage"</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
        <span class="token property">"offload_optimizer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"device"</span><span class="token operator">:</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
            <span class="token property">"pin_memory"</span><span class="token operator">:</span> <span class="token boolean">true</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        <span class="token property">"offload_param"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"device"</span><span class="token operator">:</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
            <span class="token property">"pin_memory"</span><span class="token operator">:</span> <span class="token boolean">true</span>
        <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
        <span class="token property">"overlap_comm"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
        <span class="token property">"contiguous_gradients"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
        <span class="token property">"sub_group_size"</span><span class="token operator">:</span> <span class="token number">1e9</span><span class="token punctuation">,</span>
        <span class="token property">"reduce_bucket_size"</span><span class="token operator">:</span> <span class="token number">1e6</span><span class="token punctuation">,</span>
        <span class="token property">"stage3_prefetch_bucket_size"</span><span class="token operator">:</span> <span class="token number">0.94e6</span><span class="token punctuation">,</span>
        <span class="token property">"stage3_param_persistence_threshold"</span><span class="token operator">:</span> <span class="token number">1e4</span><span class="token punctuation">,</span>
        <span class="token property">"stage3_max_live_parameters"</span><span class="token operator">:</span> <span class="token number">1e9</span><span class="token punctuation">,</span>
        <span class="token property">"stage3_max_reuse_distance"</span><span class="token operator">:</span> <span class="token number">1e9</span><span class="token punctuation">,</span>
        <span class="token property">"stage3_gather_16bit_weights_on_model_save"</span><span class="token operator">:</span> <span class="token boolean">true</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
 
    <span class="token property">"steps_per_print"</span><span class="token operator">:</span> <span class="token number">2000</span><span class="token punctuation">,</span>
    <span class="token property">"wall_clock_breakdown"</span><span class="token operator">:</span> <span class="token boolean">false</span>
<span class="token punctuation">&#125;</span></pre></div></code-block><h3 id="5B7TQ2451HpnmniAatr6Su" class="wolai-block"><span class="inline-wrap">4.2 deepspeed+transformer<span class="jill"></span>代码实战</span></h3><h4 id="jm8tHU2DDmGvpoUqrxEpHJ" class="wolai-block"><span class="inline-wrap">（1）预处理和<span class="jill"></span>Json<span class="jill"></span>文件</span></h4><div id="b7pMMN3dHVRDmLMaJNRSFG" class="wolai-block wolai-text"><div><span class="inline-wrap">首先是利用<span class="jill"></span>huggingface<span class="jill"></span>的<span class="jill"></span>datasets.map<span class="jill"></span>对数据集的样本自定义操作；transformers<span class="jill"></span>可以通过<span class="jill"></span>trainer<span class="jill"></span>集成<span class="jill"></span>deepspeed<span class="jill"></span>功能，这种用法需要提供配置文件，如下面的<span class="jill"></span>deepspeed<span class="jill"></span>配置文件<span class="jill"></span>ds_config.json<span class="jill"></span>文件。关于这个<span class="jill"></span>config<span class="jill"></span>具体配置可参考文档。  </span></div></div><div id="9VARqnh8woeCtfCZqcdYtB" class="wolai-block wolai-text"><div><span class="inline-wrap">这里用的<span class="jill"></span>FLAN-T5<span class="jill"></span>模型；启动<span class="jill"></span>deepspeed：deepspeed --include=localhost:1,2 </span><span class="inline-wrap"><a target="_blank" rel="noopener" href="http://train.py"><span>train.py</span></a></span><span class="inline-wrap">，启动前两张显卡；注意使用<span class="jill"></span>ZeRO3<span class="jill"></span>需要有足够的内存  </span></div></div><div id="CqZeWKut3tbui8a9zgFJL" class="wolai-block wolai-text"><div><span class="inline-wrap">如果不使用<span class="jill"></span>trianer<span class="jill"></span>来集成<span class="jill"></span>deepspeed，from_pretrained<span class="jill"></span>和 from_config<span class="jill"></span>这样的核心功能应该包含<span class="jill"></span>DeepSpeed<span class="jill"></span>中的重要部分，例如<span class="jill"></span>zero。初始化<span class="jill"></span>Zero<span class="jill"></span>的时候应该为<span class="jill"></span>stage3<span class="jill"></span>或者更高。参考文档。  </span></div></div><code-block id="j8pV5iRcxDacoL4XvKaYFR" class="wolai-block"><div class="wolai-pre"><div data-lang="JSON" class="marker"></div><pre><span class="token punctuation">&#123;</span>
  <span class="token property">"bf16"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"enabled"</span><span class="token operator">:</span> <span class="token string">"auto"</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"optimizer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"AdamW"</span><span class="token punctuation">,</span>
    <span class="token property">"params"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
      <span class="token property">"lr"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"betas"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"eps"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"weight_decay"</span><span class="token operator">:</span> <span class="token string">"auto"</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"scheduler"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"WarmupLR"</span><span class="token punctuation">,</span>
    <span class="token property">"params"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
      <span class="token property">"warmup_min_lr"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"warmup_max_lr"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"warmup_num_steps"</span><span class="token operator">:</span> <span class="token string">"auto"</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"zero_optimization"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"stage"</span><span class="token operator">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
    <span class="token property">"offload_optimizer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
      <span class="token property">"device"</span><span class="token operator">:</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
      <span class="token property">"pin_memory"</span><span class="token operator">:</span> <span class="token boolean">true</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token property">"offload_param"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
      <span class="token property">"device"</span><span class="token operator">:</span> <span class="token string">"cpu"</span><span class="token punctuation">,</span>
      <span class="token property">"pin_memory"</span><span class="token operator">:</span> <span class="token boolean">true</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token property">"overlap_comm"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
    <span class="token property">"contiguous_gradients"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
    <span class="token property">"sub_group_size"</span><span class="token operator">:</span> <span class="token number">1e9</span><span class="token punctuation">,</span>
    <span class="token property">"reduce_bucket_size"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
    <span class="token property">"stage3_prefetch_bucket_size"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
    <span class="token property">"stage3_param_persistence_threshold"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
    <span class="token property">"stage3_max_live_parameters"</span><span class="token operator">:</span> <span class="token number">1e9</span><span class="token punctuation">,</span>
    <span class="token property">"stage3_max_reuse_distance"</span><span class="token operator">:</span> <span class="token number">1e9</span><span class="token punctuation">,</span>
    <span class="token property">"stage3_gather_16bit_weights_on_model_save"</span><span class="token operator">:</span> <span class="token boolean">false</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"gradient_accumulation_steps"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
  <span class="token property">"gradient_clipping"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
  <span class="token property">"steps_per_print"</span><span class="token operator">:</span> <span class="token number">2000</span><span class="token punctuation">,</span>
  <span class="token property">"train_batch_size"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
  <span class="token property">"train_micro_batch_size_per_gpu"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
  <span class="token property">"wall_clock_breakdown"</span><span class="token operator">:</span> <span class="token boolean">false</span>
<span class="token punctuation">&#125;</span></pre></div></code-block><h4 id="5H8wxFVBShZ5yyhNhw92tu" class="wolai-block"><span class="inline-wrap">（2）训练代码</span></h4><ul class="wolai-block"><li id="rTgree8okHN1FhkcYuE4Xf"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">数据：samsum<span class="jill"></span>数据集</span></li><li id="hWnxTdpZ96f2ydpBRsBgCv"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">模型：google/flan-t5-xxl<span class="jill"></span>大模型</span></li></ul><code-block id="2qXUoquvbqmBKrtK5ABBwG" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token comment"># !/usr/bin/python</span>
<span class="token comment"># -*- coding: utf-8 -*-</span>
 
<span class="token keyword">import</span> nltk
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> evaluate
<span class="token keyword">import</span> datasets
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>rnn <span class="token keyword">import</span> pad_sequence
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Seq2SeqTrainer<span class="token punctuation">,</span> Seq2SeqTrainingArguments
 
nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">"punkt"</span><span class="token punctuation">)</span>
 
dataset_name <span class="token operator">=</span> <span class="token string">"samsum"</span> <span class="token comment"># 数据集名称</span>
model_name<span class="token operator">=</span><span class="token string">"google/flan-t5-xxl"</span> <span class="token comment"># 模型名称</span>
max_input_length <span class="token operator">=</span> <span class="token number">512</span>
max_gen_length <span class="token operator">=</span> <span class="token number">128</span>
output_dir <span class="token operator">=</span> <span class="token string">"checkpoints"</span>
num_train_epochs <span class="token operator">=</span> <span class="token number">5</span>
learning_rate <span class="token operator">=</span> <span class="token number">5e-5</span>
deepspeed_config <span class="token operator">=</span> <span class="token string">"./ds_config.json"</span> <span class="token comment"># deepspeed配置文件</span>
per_device_train_batch_size<span class="token operator">=</span><span class="token number">1</span> <span class="token comment"># batch size设置为1，因为太大导致OOM</span>
per_device_eval_batch_size<span class="token operator">=</span><span class="token number">1</span>
gradient_accumulation_steps<span class="token operator">=</span><span class="token number">2</span> <span class="token comment"># 由于单卡的batch size为1，为了扩展batch size，使用梯度累加</span>
 
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>
 
<span class="token comment"># 加载数据</span>
dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span>dataset_name<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 
<span class="token comment"># tokenize</span>
<span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>examples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    dialogues <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"summarize:"</span> <span class="token operator">+</span> dia <span class="token keyword">for</span> dia <span class="token keyword">in</span> examples<span class="token punctuation">[</span><span class="token string">"dialogue"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token comment"># summaries = [summ for summ in examples["summary"]]</span>
    model_inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>dialogues<span class="token punctuation">,</span> max_length<span class="token operator">=</span>max_input_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text_target<span class="token operator">=</span>examples<span class="token punctuation">[</span><span class="token string">"summary"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>max_gen_length<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    model_inputs<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> model_inputs
 
tokenized_dataset <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>preprocess<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> remove_columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"dialogue"</span><span class="token punctuation">,</span> <span class="token string">"summary"</span><span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># print(tokenized_dataset["train"]["input_ids"][0]) # 打印结果</span>
 
 
<span class="token comment"># 对batch进行padding</span>
<span class="token keyword">def</span> <span class="token function">collate_fn</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch_input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>feature<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features<span class="token punctuation">]</span>
    batch_attention_mask <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>feature<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features<span class="token punctuation">]</span>
    batch_labels <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>feature<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> feature <span class="token keyword">in</span> features<span class="token punctuation">]</span>
 
    batch_input_ids <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>batch_input_ids<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_value<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span>
    batch_attention_mask <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>batch_attention_mask<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    batch_labels <span class="token operator">=</span> pad_sequence<span class="token punctuation">(</span>batch_labels<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> padding_value<span class="token operator">=</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">)</span>
 
    <span class="token keyword">return</span> <span class="token punctuation">&#123;</span>
        <span class="token string">"input_ids"</span><span class="token punctuation">:</span> batch_input_ids<span class="token punctuation">,</span>
        <span class="token string">"attention_mask"</span><span class="token punctuation">:</span> batch_attention_mask<span class="token punctuation">,</span>
        <span class="token string">"labels"</span><span class="token punctuation">:</span> batch_labels
    <span class="token punctuation">&#125;</span>
<span class="token comment"># 用于测试的代码</span>
<span class="token comment"># dataloader = DataLoader(tokenized_dataset["test"], shuffle=False, batch_size=4, collate_fn=collate_fn)</span>
<span class="token comment"># batch = next(iter(dataloader))</span>
<span class="token comment"># print(batch)</span>
 
 
<span class="token comment"># 加载模型</span>
model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>
<span class="token comment"># 用于测试的代码</span>
<span class="token comment"># dataloader = DataLoader(tokenized_dataset["test"], shuffle=False, batch_size=4, collate_fn=collate_fn)</span>
<span class="token comment"># batch = next(iter(dataloader))</span>
<span class="token comment"># output = model(**batch)</span>
<span class="token comment"># print(output)</span>
 
 
<span class="token comment"># 定义评估函数</span>
metric <span class="token operator">=</span> evaluate<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"rouge"</span><span class="token punctuation">)</span>
 
<span class="token keyword">def</span> <span class="token function">compute_metrics</span><span class="token punctuation">(</span>eval_preds<span class="token punctuation">)</span><span class="token punctuation">:</span>
    preds<span class="token punctuation">,</span> labels <span class="token operator">=</span> eval_preds
    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>preds<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        preds <span class="token operator">=</span> preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    decoded_preds <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    labels <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>labels <span class="token operator">!=</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">,</span> labels<span class="token punctuation">,</span> tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span>
    decoded_labels <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    decoded_preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sent_tokenize<span class="token punctuation">(</span>pred<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> pred <span class="token keyword">in</span> decoded_preds<span class="token punctuation">]</span>
    decoded_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>sent_tokenize<span class="token punctuation">(</span>label<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> label <span class="token keyword">in</span> decoded_labels<span class="token punctuation">]</span>
    result <span class="token operator">=</span> metric<span class="token punctuation">.</span>compute<span class="token punctuation">(</span>predictions<span class="token operator">=</span>decoded_preds<span class="token punctuation">,</span> references<span class="token operator">=</span>decoded_labels<span class="token punctuation">,</span> use_stemmer<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span>k<span class="token punctuation">:</span> <span class="token builtin">round</span><span class="token punctuation">(</span>v <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> result<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">&#125;</span>
    prediction_lens <span class="token operator">=</span> <span class="token punctuation">[</span>np<span class="token punctuation">.</span>count_nonzero<span class="token punctuation">(</span>pred <span class="token operator">!=</span> tokenizer<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">)</span> <span class="token keyword">for</span> pred <span class="token keyword">in</span> preds<span class="token punctuation">]</span>
    result<span class="token punctuation">[</span><span class="token string">"gen_len"</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>prediction_lens<span class="token punctuation">)</span>
    <span class="token keyword">return</span> result
 
 
<span class="token comment"># 设置训练参数</span>
training_args <span class="token operator">=</span> Seq2SeqTrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span>output_dir<span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span>per_device_train_batch_size<span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span>per_device_eval_batch_size<span class="token punctuation">,</span>
    gradient_accumulation_steps<span class="token operator">=</span>gradient_accumulation_steps<span class="token punctuation">,</span>
    eval_accumulation_steps<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># 防止评估时导致OOM</span>
    predict_with_generate<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span>learning_rate<span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span>num_train_epochs<span class="token punctuation">,</span>
    <span class="token comment"># logging &amp; evaluation strategies</span>
    logging_dir<span class="token operator">=</span><span class="token string">"logs"</span><span class="token punctuation">,</span>
    logging_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>
    logging_steps<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> <span class="token comment"># 每50个step打印一次log</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>
    eval_steps<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token comment"># 每500个step进行一次评估</span>
    save_steps<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>
    save_total_limit<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
    load_best_model_at_end<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    deepspeed<span class="token operator">=</span>deepspeed_config<span class="token punctuation">,</span> <span class="token comment"># deepspeed配置文件的位置</span>
    report_to<span class="token operator">=</span><span class="token string">"all"</span>
<span class="token punctuation">)</span>
 
 
<span class="token comment"># 模型训练</span>
trainer <span class="token operator">=</span> Seq2SeqTrainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_dataset<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>collate_fn<span class="token punctuation">,</span>
    compute_metrics<span class="token operator">=</span>compute_metrics<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
 
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 打印验证集上的结果</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>trainer<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>tokenized_dataset<span class="token punctuation">[</span><span class="token string">"validation"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 打印测试集上的结果</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>trainer<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>tokenized_dataset<span class="token punctuation">[</span><span class="token string">"test"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 保存最优模型</span>
trainer<span class="token punctuation">.</span>save_model<span class="token punctuation">(</span><span class="token string">"best"</span><span class="token punctuation">)</span></pre></div></code-block><div id="crEUaTGL1JM7yPEdENQCJh" class="wolai-block wolai-text"><div><span class="inline-wrap">加速训练方法：量化</span><span class="inline-wrap"><a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?q=工具包&amp;spm=1001.2101.3001.7020"><span>工具包</span></a></span><span class="inline-wrap">bitsandbytes、deepspeed（先读<span class="jill"></span>torch.distributed<span class="jill"></span>和<span class="jill"></span>ColossalAI<span class="jill"></span>在搞）、llama.cpp<span class="jill"></span>量化模型</span></div></div><h3 id="tMKaE1cUi6MzJQiL7edFhM" class="wolai-block"><span class="inline-wrap">4.3 deepspeed<span class="jill"></span>加速<span class="jill"></span>Bloom lora<span class="jill"></span>微调</span></h3><h4 id="cXUv4LiPnryfc4re7WigZh" class="wolai-block"><span class="inline-wrap">（1）配置文件</span></h4><code-block id="dYS5wWgYaDcHrkk9j1r7zo" class="wolai-block"><div class="wolai-pre"><div data-lang="JSON" class="marker"></div><pre><span class="token punctuation">&#123;</span>
  <span class="token property">"train_micro_batch_size_per_gpu"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
  <span class="token property">"gradient_accumulation_steps"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
  <span class="token property">"steps_per_print"</span><span class="token operator">:</span> <span class="token number">50</span><span class="token punctuation">,</span>
  <span class="token property">"gradient_clipping"</span><span class="token operator">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
  <span class="token property">"zero_optimization"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"stage"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token property">"offload_optimizer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
            <span class="token property">"device"</span><span class="token operator">:</span> <span class="token string">"cpu"</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token property">"contiguous_gradients"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
    <span class="token property">"overlap_comm"</span><span class="token operator">:</span> <span class="token boolean">true</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"zero_allow_untested_optimizer"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
  <span class="token property">"fp16"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"enabled"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
    <span class="token property">"loss_scale"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
    <span class="token property">"loss_scale_window"</span><span class="token operator">:</span> <span class="token number">1000</span><span class="token punctuation">,</span>
    <span class="token property">"hysteresis"</span><span class="token operator">:</span> <span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token property">"min_loss_scale"</span><span class="token operator">:</span> <span class="token number">1</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"optimizer"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"Adam"</span><span class="token punctuation">,</span>
    <span class="token property">"params"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
      <span class="token property">"lr"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"betas"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"eps"</span><span class="token operator">:</span> <span class="token string">"auto"</span><span class="token punctuation">,</span>
      <span class="token property">"weight_decay"</span><span class="token operator">:</span> <span class="token string">"auto"</span>
    <span class="token punctuation">&#125;</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"activation_checkpointing"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>
    <span class="token property">"partition_activations"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
    <span class="token property">"contiguous_memory_optimization"</span><span class="token operator">:</span> <span class="token boolean">true</span>
  <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
  <span class="token property">"wall_clock_breakdown"</span><span class="token operator">:</span> <span class="token boolean">false</span>
<span class="token punctuation">&#125;</span></pre></div></code-block><h4 id="sSiDWLC2p7pBXgxbuBvDvp" class="wolai-block"><span class="inline-wrap">（2）训练代码</span></h4><ul class="wolai-block"><li id="p6ktixGCiLRjP46Nv8GLEh"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">数据：使用<span class="jill"></span>BELLE<span class="jill"></span>提供的<span class="jill"></span>100<span class="jill"></span>万条指令微调数据</span></li><li id="4LovaSU9SBxx8aSw8Z25sW"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">模型：bloomz-7b1-mt<span class="jill"></span>模型</span></li></ul><div id="vuiNo3p1ks6W3rZV2eE8S" class="wolai-block wolai-text"><div><span class="inline-wrap"><code>deepspeed --include=localhost:0,1,2,3 train.py</code></span><span class="inline-wrap">启动</span></div></div><code-block id="r4PAQnV2GGdYXiTHfcK9ba" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token comment">#!/usr/bin/env python</span>
<span class="token comment"># -*- coding: utf-8 -*-</span>
 
<span class="token keyword">import</span> os
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> random
<span class="token keyword">import</span> datasets
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm
<span class="token keyword">from</span> typing <span class="token keyword">import</span> Dict
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> <span class="token punctuation">(</span>
    AutoModelForCausalLM<span class="token punctuation">,</span>
    AutoTokenizer<span class="token punctuation">,</span>
    DataCollatorForSeq2Seq<span class="token punctuation">,</span>
    TrainingArguments<span class="token punctuation">,</span>
    Trainer
<span class="token punctuation">)</span>
<span class="token keyword">from</span> peft <span class="token keyword">import</span> <span class="token punctuation">(</span>
    LoraConfig<span class="token punctuation">,</span>
    TaskType<span class="token punctuation">,</span>
    get_peft_model<span class="token punctuation">,</span>
    get_peft_model_state_dict<span class="token punctuation">,</span>
    set_peft_model_state_dict
<span class="token punctuation">)</span>
 
<span class="token keyword">def</span> <span class="token function">set_random_seed</span><span class="token punctuation">(</span>seed<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> seed <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> seed <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>random<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>manual_seed_all<span class="token punctuation">(</span>seed<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">True</span>
 
set_random_seed<span class="token punctuation">(</span><span class="token number">1234</span><span class="token punctuation">)</span>
 
<span class="token comment"># 1. 设置参数</span>
<span class="token comment"># LoRA参数</span>
LORA_R <span class="token operator">=</span> <span class="token number">8</span>
LORA_ALPHA <span class="token operator">=</span> <span class="token number">32</span>
LORA_DROPOUT <span class="token operator">=</span> <span class="token number">0.1</span>
<span class="token comment"># 训练参数</span>
EPOCHS<span class="token operator">=</span><span class="token number">3</span>
LEARNING_RATE<span class="token operator">=</span><span class="token number">5e-5</span>
OUTPUT_DIR<span class="token operator">=</span><span class="token string">"./checkpoints"</span>
BATCH_SIZE<span class="token operator">=</span><span class="token number">4</span> <span class="token comment"># 2</span>
GRADIENT_ACCUMULATION_STEPS<span class="token operator">=</span><span class="token number">3</span>
<span class="token comment"># 其他参数</span>
MODEL_PATH <span class="token operator">=</span> <span class="token string">"bigscience/bloomz-7b1-mt"</span>
DATA_PATH <span class="token operator">=</span> <span class="token string">"./data/belle_open_source_1M.train.json"</span>
MAX_LENGTH <span class="token operator">=</span> <span class="token number">512</span>
PATTERN <span class="token operator">=</span> <span class="token string">"{}\n{}"</span>
DS_CONFIG <span class="token operator">=</span> <span class="token string">"ds_zero2_config.json"</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>MODEL_PATH<span class="token punctuation">)</span> <span class="token comment"># 加载tokenizer</span>
<span class="token comment"># 加载数据</span>
dataset <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_dataset<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">,</span> data_files<span class="token operator">=</span>DATA_PATH<span class="token punctuation">)</span>
<span class="token comment"># print(dataset["train"][0])</span>
 
 
<span class="token comment"># 2. tokenize</span>
<span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> add_eos_token<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    result <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
        text<span class="token punctuation">,</span>
        truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">,</span>
        padding<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
        return_tensors<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
    <span class="token comment"># 判断是否要添加eos_token</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">!=</span> tokenizer<span class="token punctuation">.</span>eos_token_id
        <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> MAX_LENGTH
        <span class="token keyword">and</span> add_eos_token<span class="token punctuation">)</span><span class="token punctuation">:</span>
        result<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">)</span>
        result<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    result<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> result<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> result
 
 
<span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>example<span class="token punctuation">:</span> Dict<span class="token punctuation">,</span> train_on_inputs<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    prompt <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span>
    response <span class="token operator">=</span> example<span class="token punctuation">[</span><span class="token string">"target"</span><span class="token punctuation">]</span>
    text <span class="token operator">=</span> PATTERN<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> response<span class="token punctuation">)</span>
    tokenized_inp <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    <span class="token comment"># 若train_on_inputs为False，则将label中与input相关的token替换为-100</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> train_on_inputs<span class="token punctuation">:</span>
        tokenized_prompt <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span>add_eos_token<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        prompt_tokens_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokenized_prompt<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        tokenized_inp<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token operator">*</span>prompt_tokens_len <span class="token operator">+</span> tokenized_inp<span class="token punctuation">[</span><span class="token string">"labels"</span><span class="token punctuation">]</span><span class="token punctuation">[</span>prompt_tokens_len<span class="token punctuation">:</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> tokenized_inp
 
 
train_data <span class="token operator">=</span> dataset<span class="token punctuation">[</span><span class="token string">"train"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>preprocess<span class="token punctuation">,</span> remove_columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"input"</span><span class="token punctuation">,</span> <span class="token string">"target"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
 
<span class="token comment"># pad_to_multiple_of=8表示padding的长度是8的倍数</span>
collate_fn <span class="token operator">=</span> DataCollatorForSeq2Seq<span class="token punctuation">(</span>tokenizer<span class="token punctuation">,</span> pad_to_multiple_of<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
 
<span class="token comment"># 2. 加载模型</span>
evice_map <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">""</span><span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"LOCAL_RANK"</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
<span class="token comment"># device_map指定模型加载的GPU;troch_dtype=torch.float16表示半精度加载模型</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>MODEL_PATH<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">,</span> device_map<span class="token operator">=</span>device_map<span class="token punctuation">)</span>
 
 
<span class="token comment"># 3. LoRA相关</span>
lora_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
    task_type<span class="token operator">=</span>TaskType<span class="token punctuation">.</span>CAUSAL_LM<span class="token punctuation">,</span>
    inference_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
    r<span class="token operator">=</span>LORA_R<span class="token punctuation">,</span> <span class="token comment"># LoRA中低秩近似的秩</span>
    lora_alpha<span class="token operator">=</span>LORA_ALPHA<span class="token punctuation">,</span> <span class="token comment"># 见上文中的低秩矩阵缩放超参数</span>
    lora_dropout<span class="token operator">=</span>LORA_DROPOUT<span class="token punctuation">,</span> <span class="token comment"># LoRA层的dropout</span>
<span class="token punctuation">)</span>
<span class="token comment"># 转换模型</span>
model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> lora_config<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>use_cache <span class="token operator">=</span> <span class="token boolean">False</span>
old_state_dict <span class="token operator">=</span> model<span class="token punctuation">.</span>state_dict
model<span class="token punctuation">.</span>state_dict <span class="token operator">=</span> <span class="token punctuation">(</span>
    <span class="token keyword">lambda</span> self<span class="token punctuation">,</span> <span class="token operator">*</span>_<span class="token punctuation">,</span> <span class="token operator">**</span>__<span class="token punctuation">:</span> get_peft_model_state_dict<span class="token punctuation">(</span>self<span class="token punctuation">,</span> old_state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span><span class="token punctuation">.</span>__get__<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 打印模型中的可训练参数</span>
model<span class="token punctuation">.</span>print_trainable_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>
 
 
<span class="token comment"># 4. 训练参数</span>
args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span>OUTPUT_DIR<span class="token punctuation">,</span> <span class="token comment"># checkpoint的存储目录</span>
    per_device_train_batch_size<span class="token operator">=</span>BATCH_SIZE<span class="token punctuation">,</span> <span class="token comment"># 单设备上的batch size</span>
    gradient_accumulation_steps<span class="token operator">=</span>GRADIENT_ACCUMULATION_STEPS<span class="token punctuation">,</span> <span class="token comment"># 梯度累加的step数</span>
    warmup_steps<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
    num_train_epochs<span class="token operator">=</span>EPOCHS<span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span>LEARNING_RATE<span class="token punctuation">,</span>
    fp16<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment"># 使用混合精度训练</span>
    logging_steps<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
    evaluation_strategy<span class="token operator">=</span><span class="token string">"no"</span><span class="token punctuation">,</span> <span class="token comment"># 不进行评估</span>
    save_strategy<span class="token operator">=</span><span class="token string">"steps"</span><span class="token punctuation">,</span>
    save_steps<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span> <span class="token comment"># 保存checkpoint的step数</span>
    save_total_limit<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token comment"># 最多保存5个checkpoint</span>
    deepspeed<span class="token operator">=</span>DS_CONFIG
<span class="token punctuation">)</span>
 
 
<span class="token comment"># 5. 模型训练</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>train_data<span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    args<span class="token operator">=</span>args<span class="token punctuation">,</span>
    data_collator<span class="token operator">=</span>collate_fn
<span class="token punctuation">)</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">"best_model"</span><span class="token punctuation">)</span></pre></div></code-block><div id="cBZUtAHYnrpz5BSWT3XMD5" class="wolai-block wolai-text"><div><span class="inline-wrap"><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_35812205/article/details/131607096"><span>【LLM】DeepSpeed<span class="jill"></span>分布式训练框架_山顶夕景的博客-CSDN<span class="jill"></span>博客</span></a></span></div></div><div id="cmG5DGp3i3TN3HQV55F76B" class="wolai-block wolai-text"><div><span class="inline-wrap"></span><br/></div></div></article><footer></footer></body></html></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/wdn_icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Dongnian</div><div class="author-info__description">A salty fish swimming in the sea of deep learning!</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">87</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wdndev"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/wdndev" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:dongnian.wang@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #24292e;"></i></a><a class="social-icon" href="https://blog.csdn.net/wdnshadow" target="_blank" title="CSDN"><i class="fas fa-rss" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Welcome to My Personal Blog! <br /> If Not, Please Visit <a target="_blank" rel="noopener" href="https://wdndev.gitee.io/"> <font color=#00BFFF>Gitee Mirror</font></a>.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#t3W59DWgAv41PLZGSrUnRz"><span class="toc-text">1.Deepspeed</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#tsSuzK6xhbyXSnsgBdABQs"><span class="toc-text">1.1  基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#75UGgW25hGJ39v9wHTB9e2"><span class="toc-text">1.2 通信策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gkM4vUCMkbiLsA7TMvCYQV"><span class="toc-text">1.3 DeepSpeed训练介绍</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ig5iSNH3R3Cey2NkNUsyHM"><span class="toc-text">2. Zero（3D优化与卸载）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ibma9eQWXQZhufgQiHNaxG"><span class="toc-text">2.1 三个级别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nRaQAqFr6UNLx69aKemfpW"><span class="toc-text">2.2 混合精度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9yPmGUpQzDBWPZXybGUHhX"><span class="toc-text">2.3 显存占用分析</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4F6ByGG7GqFNJRa4meszB9"><span class="toc-text">（1）模型状态（model states）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rMhdp7EpX6w3jQtnw6pPog"><span class="toc-text">（2）剩余状态（residual states）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#wn52LhpJchJA4zaajvHGF2"><span class="toc-text">3.ZeRO-DP</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#un9yecSH9d1NotAxnsJBw4"><span class="toc-text">3.1 ZeRO-DP的细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#aYnE1aVFw5tBqceWmXMQ6K"><span class="toc-text">3.2 ZeRO-DP通信量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#9usaLf9acdRsrssLqd5kwJ"><span class="toc-text">（1）标准数据并行的通信量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mPdZYebybL7EFCPqXrq1pm"><span class="toc-text">（2）Zero-DP的通信量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3Azr3FC9QLm4f6vMRmy7NN"><span class="toc-text">4.DeepSpeed训练</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#dPF832kDUoMsnrUA6SCgoU"><span class="toc-text">4.1 基本训练的介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5B7TQ2451HpnmniAatr6Su"><span class="toc-text">4.2 deepspeed+transformer代码实战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#jm8tHU2DDmGvpoUqrxEpHJ"><span class="toc-text">（1）预处理和Json文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5H8wxFVBShZ5yyhNhw92tu"><span class="toc-text">（2）训练代码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tMKaE1cUi6MzJQiL7edFhM"><span class="toc-text">4.3 deepspeed加速Bloom lora微调</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cXUv4LiPnryfc4re7WigZh"><span class="toc-text">（1）配置文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sSiDWLC2p7pBXgxbuBvDvp"><span class="toc-text">（2）训练代码</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/llms/llms_article/9.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BALLM/" title="检索增强LLM">检索增强LLM</a><time datetime="2024-01-12T16:00:00.000Z" title="Created 2024-01-13 00:00:00">2024-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/llms/llms_course/6.%E6%96%87%E6%9C%AC%E7%90%86%E8%A7%A3%E5%92%8C%E7%94%9F%E6%88%90%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="LLMs公开课 - 6.文本理解和生成大模型">LLMs公开课 - 6.文本理解和生成大模型</a><time datetime="2024-01-09T16:00:00.000Z" title="Created 2024-01-10 00:00:00">2024-01-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/llms/llms_course/5.%E9%AB%98%E6%95%88%E8%AE%AD%E7%BB%83_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/" title="LLMs公开课 - 5.高效训练&amp;模型压缩">LLMs公开课 - 5.高效训练&amp;模型压缩</a><time datetime="2024-01-06T16:00:00.000Z" title="Created 2024-01-07 00:00:00">2024-01-07</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            <a class="card-more-btn" href="/categories/" title="More">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Cython/"><span class="card-category-list-name">Cython</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DSA/"><span class="card-category-list-name">DSA</span><span class="card-category-list-count">24</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LLMs/"><span class="card-category-list-name">LLMs</span><span class="card-category-list-count">16</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/PL/"><span class="card-category-list-name">PL</span><span class="card-category-list-count">7</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/PL/Cython/"><span class="card-category-list-name">Cython</span><span class="card-category-list-count">6</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/DSA/" style="font-size: 1.42em; color: rgb(91, 145, 17)">DSA</a><a href="/tags/RL/" style="font-size: 1.28em; color: rgb(176, 79, 19)">RL</a><a href="/tags/Transformer/" style="font-size: 1.45em; color: rgb(127, 170, 70)">Transformer</a><a href="/tags/LLMs/" style="font-size: 1.32em; color: rgb(112, 148, 55)">LLMs</a><a href="/tags/PaperReading/" style="font-size: 1.38em; color: rgb(110, 146, 60)">PaperReading</a><a href="/tags/DeepLearning/" style="font-size: 1.25em; color: rgb(90, 48, 1)">DeepLearning</a><a href="/tags/CV/" style="font-size: 1.15em; color: rgb(82, 200, 174)">CV</a><a href="/tags/GPT/" style="font-size: 1.18em; color: rgb(7, 16, 91)">GPT</a><a href="/tags/PL/" style="font-size: 1.22em; color: rgb(17, 30, 26)">PL</a><a href="/tags/leetcode/" style="font-size: 1.35em; color: rgb(106, 126, 145)">leetcode</a><a href="/tags/algo/" style="font-size: 1.15em; color: rgb(181, 144, 151)">algo</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span><a class="card-more-btn" href="/archives/" title="More">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">January 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">December 2023</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">November 2023</span><span class="card-archive-list-count">26</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">October 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">September 2023</span><span class="card-archive-list-count">4</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">87</div></div><div class="webinfo-item"><div class="item-name">Run time :</div><div class="item-count" id="runtimeshow" data-publishDate="2023-05-31T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">411.2k</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-12-08T03:57:10.055Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Dongnian</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">簡</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'oe7vzWxH80qwJJjWslYTCViT-gzGzoHsz',
      appKey: 'k89nSbK0BTbmzmpQottRHvNI',
      avatar: 'monsterid',
      serverURLs: 'https://oe7vzwxh.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script async src="/js/title.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":180,"height":360,"hOffset":0,"vOffset":-100},"mobile":{"show":true},"react":{"opacity":0.85},"log":false});</script></body></html>