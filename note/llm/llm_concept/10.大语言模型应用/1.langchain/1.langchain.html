<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>37.2° Blog | 37.2° Blog</title><meta name="author" content="Dongnian"><meta name="copyright" content="Dongnian"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="1.langchain - wolai 笔记[toc]1.什么是 LangChain?LangChain 是一个基于语言模型的框架，用于构建聊天机器人、生成式问答（GQA）、摘要等功能。它的核心思想是将不同的组件“链”在一起，以创建更高级的语言模型应用。LangChain 框架核心目标是为了连接多种大语言模型（如 OpenAI、LLaMA 等）和外部资源 （如 Google、Wikipedia、">
<meta property="og:type" content="website">
<meta property="og:title" content="37.2° Blog">
<meta property="og:url" content="https://wdndev.github.io/note/llm/llm_concept/10.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/1.langchain/1.langchain.html">
<meta property="og:site_name" content="37.2° Blog">
<meta property="og:description" content="1.langchain - wolai 笔记[toc]1.什么是 LangChain?LangChain 是一个基于语言模型的框架，用于构建聊天机器人、生成式问答（GQA）、摘要等功能。它的核心思想是将不同的组件“链”在一起，以创建更高级的语言模型应用。LangChain 框架核心目标是为了连接多种大语言模型（如 OpenAI、LLaMA 等）和外部资源 （如 Google、Wikipedia、">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://wdndev.github.io/img/wdn_icon.png">
<meta property="article:published_time" content="2024-12-08T03:56:28.230Z">
<meta property="article:modified_time" content="2024-12-08T03:56:28.230Z">
<meta property="article:author" content="Dongnian">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wdndev.github.io/img/wdn_icon.png"><link rel="shortcut icon" href="/img/wdn_icon.png"><link rel="canonical" href="https://wdndev.github.io/note/llm/llm_concept/10.%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8/1.langchain/1.langchain.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":400},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: 'days',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: {"limitCount":100,"languages":{"author":"Author: Dongnian","link":"Link: ","source":"Source: 37.2° Blog","info":"Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source."}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '37.2° Blog',
  isPost: false,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-12-08 11:56:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/wdn_icon.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">87</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Content</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/paper_reading/pr_content"><i class="fa-fw fas fa-newspaper"></i><span> Paper</span></a></li><li><a class="site-page child" href="/llms/llms_idx"><i class="fa-fw fa-solid fa-magnifying-glass"></i><span> LLMs</span></a></li><li><a class="site-page child" href="/jupyter"><i class="fa-fw fa-solid fa-file"></i><span> Jupyter</span></a></li><li><a class="site-page child" href="/note"><i class="fa-fw fa-regular fa-bookmark"></i><span> Note</span></a></li><li><a class="site-page child" href="/dsa/dsa_idx"><i class="fa-fw fas fa-tree"></i><span> Algorithm</span></a></li><li><a class="site-page child" href="/program_language/pl_idx"><i class="fa-fw fas fa-code"></i><span> PLs</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="not-top-img fixed" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="37.2° Blog"><span class="site-name">37.2° Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> Content</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/paper_reading/pr_content"><i class="fa-fw fas fa-newspaper"></i><span> Paper</span></a></li><li><a class="site-page child" href="/llms/llms_idx"><i class="fa-fw fa-solid fa-magnifying-glass"></i><span> LLMs</span></a></li><li><a class="site-page child" href="/jupyter"><i class="fa-fw fa-solid fa-file"></i><span> Jupyter</span></a></li><li><a class="site-page child" href="/note"><i class="fa-fw fa-regular fa-bookmark"></i><span> Note</span></a></li><li><a class="site-page child" href="/dsa/dsa_idx"><i class="fa-fw fas fa-tree"></i><span> Algorithm</span></a></li><li><a class="site-page child" href="/program_language/pl_idx"><i class="fa-fw fas fa-code"></i><span> PLs</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="page"><h1 class="page-title"></h1><div id="article-container"><!DOCTYPE html>
<html lang="zh-Hans-CN"><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=Edge"/><link rel="stylesheet" type="text/css" href="../../css/modern-norm.min.css"/><link rel="stylesheet" type="text/css" href="../../css/prism.min.css"/><link rel="stylesheet" type="text/css" href="../../css/katex.min.css"/><link rel="stylesheet" type="text/css" href="../../css/wolai.css"/><title>1.langchain - wolai 笔记</title><link rel="shortcut icon" href="data:image/svg+xml,%3Csvg xmlns=&apos;http://www.w3.org/2000/svg&apos; viewBox=&apos;0 0 800 800&apos;%3E%3Cdefs%3E%3Cstyle%3E.cls-1%7Bfill:%23fff;%7D%3C/style%3E%3C/defs%3E%3Cg%3E%3Cpath class=&apos;cls-1&apos; d=&apos;M610.08,0c66,0,90,6.88,114.13,19.79a134.62,134.62,0,0,1,56,56l2.28,4.4C793.93,103,800,127.88,800,189.92V610.08l-.08,11.56c-.78,57.38-7.58,79.89-19.71,102.57a134.62,134.62,0,0,1-56,56l-4.4,2.28C697,793.93,672.12,800,610.08,800H189.92l-11.56-.08c-57.38-.78-79.89-7.58-102.57-19.71a134.62,134.62,0,0,1-56-56l-2.28-4.4C6.44,697.75.4,673.72,0,616L0,189.92c0-66,6.88-90,19.79-114.13a134.62,134.62,0,0,1,56-56l4.4-2.28C102.25,6.44,126.28.4,184,0Z&apos;/%3E%3Cpath d=&apos;M610.08,0c66,0,90,6.88,114.13,19.79a134.62,134.62,0,0,1,56,56l2.28,4.4C793.93,103,800,127.88,800,189.92V610.08l-.08,11.56c-.78,57.38-7.58,79.89-19.71,102.57a134.62,134.62,0,0,1-56,56l-4.4,2.28C697,793.93,672.12,800,610.08,800H189.92l-11.56-.08c-57.38-.78-79.89-7.58-102.57-19.71a134.62,134.62,0,0,1-56-56l-2.28-4.4C6.44,697.75.4,673.72,0,616L0,189.92c0-66,6.88-90,19.79-114.13a134.62,134.62,0,0,1,56-56l4.4-2.28C102.25,6.44,126.28.4,184,0Zm4.72,88.9H185.2L172.42,89c-32.78.62-43.68,3.24-54.71,9.14a45.84,45.84,0,0,0-19.54,19.54c-6.61,12.36-9.11,24.55-9.27,67.49V614.8L89,627.58c.62,32.78,3.24,43.68,9.14,54.71a45.84,45.84,0,0,0,19.54,19.54c12.36,6.61,24.55,9.11,67.49,9.27H610.08c46.79,0,59.41-2.44,72.21-9.28a45.84,45.84,0,0,0,19.54-19.54c6.61-12.36,9.11-24.55,9.27-67.49V189.92c0-46.79-2.44-59.41-9.28-72.21a45.84,45.84,0,0,0-19.54-19.54C669.93,91.56,657.74,89.06,614.8,88.9ZM233.33,493.33A73.34,73.34,0,1,1,160,566.67,73.35,73.35,0,0,1,233.33,493.33Z&apos;/%3E%3C/g%3E%3C/svg%3E"></link></head><body><header><div class="image"></div><div class="title"><div class="banner"><div class="icon"></div></div><div data-title="1.langchain" class="main-title"></div></div></header><article><div id="fvhcNgk1Xh9uNtRtZtZ6NN" class="wolai-block wolai-text"><div><span class="inline-wrap">[toc]</span></div></div><h3 id="6qZxn3rdExgpRf2GapUNpy" class="wolai-block"><span class="inline-wrap">1.什么是 LangChain?</span></h3><div id="n1sFwuJSbGGu7jVzMNoQaV" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 是一个基于语言模型的框架，用于构建聊天机器人、生成式问答（GQA）、摘要等功能。它的核心思想是将不同的组件“链”在一起，以创建更高级的语言模型应用。</span></div></div><div id="mwApZHyvV5W7Ak9fL9Wq3z" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 框架核心目标是</span><span class="red inline-wrap"><b>为了连接多种大语言模型</b></span><span class="inline-wrap">（如 OpenAI、LLaMA 等）</span><span class="red inline-wrap"><b>和外部资源 </b></span><span class="inline-wrap">（如 Google、Wikipedia、Notion 以及 Wolfram 等），</span><span class="red inline-wrap"><b>提供抽象和工具以在文本输入和输出之间进行接口处理</b></span><span class="inline-wrap">。大语言模型和组件通过“链（Chain）”连接，使得开发人员可以快速开发原型系统和 应用程序。</span></div></div><div id="e9ro2agrYuNCu45iQSxSTx" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 的主要价值在于以下几个方面： </span></div></div><ol class="wolai-block"><li id="as5LkhrpWVTwN3Q4qr5sH5"><div class="marker"></div><span class="red inline-wrap"><b>组件化</b></span><span class="inline-wrap">：LangChain 框架提供了用于处理语言模型的抽象组件，以及每个抽象组件的一系列 实现。这些组件具有模块化设计，易于使用，无论是否使用 LangChain 框架的其他部分，都 可以方便地使用这些组件。</span></li><li id="dPJX7neS1mbNXf2PSDNTvL"><div class="marker"></div><span class="red inline-wrap"><b>现成的链式组装</b></span><span class="inline-wrap">：LangChain 框架提供了一些现成的链式组装，用于完成特定的高级任务。这 些现成的链式组装使得入门变得更加容易。对于更复杂的应用程序，LangChain 框架也支持 自定义现有链式组装或构建新的链式组装。</span></li><li id="nadGPr7RqWpsiz3U2vsdp3"><div class="marker"></div><span class="red inline-wrap"><b>简化开发难度</b></span><span class="inline-wrap">：通过提供组件化和现成的链式组装，LangChain 框架可以大大简化大语言模 型应用的开发难度。开发人员可以更专注于业务逻辑，而无需花费大量时间和精力处理底层 技术细节。</span></li></ol><h3 id="qhgae5g4pQwCgkXLZH5J4z" class="wolai-block"><span class="inline-wrap">2. LangChain 包含哪些核心模块</span></h3><div id="vfJS43n9rLGyEUoA9PwxDw" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 的提供了以下 6 种标准化、可扩展的接口并且可以外部集成的核心模块：</span></div></div><ol class="wolai-block"><li id="3Xc3YQCrmcFKbv4JKMTnuj"><div class="marker"></div><span class="yellow inline-wrap"><b>模型输 入/输出（Model I/O）</b></span><span class="inline-wrap">：与语言模型交互的接口；</span></li><li id="jKVddRY6gv2MXeyzrcGopd"><div class="marker"></div><span class="yellow inline-wrap"><b>数据连接（Data connection）</b></span><span class="inline-wrap">：与特定应用程序的数 据进行交互的接口；</span></li><li id="3XEJcff5AiHUcGZmKT5Xgw"><div class="marker"></div><span class="yellow inline-wrap"><b>链（Chains）</b></span><span class="inline-wrap">：用于复杂的应用的调用序列；</span></li><li id="a3JmNBFFNZZRzce5jYHY1m"><div class="marker"></div><span class="yellow inline-wrap"><b>智能体（Agents）</b></span><span class="inline-wrap">：语言模型作为推理器决定要执行的动作序列；</span></li><li id="iEQNgeYWURXQRkcDboGtJ6"><div class="marker"></div><span class="yellow inline-wrap"><b>记忆（Memory）</b></span><span class="inline-wrap">：用于链的多次运行之间持久化应用程序状态；</span></li><li id="sGQnpUCznioHDhGvBCLhEs"><div class="marker"></div><span class="yellow inline-wrap"><b>回调 （Callbacks）</b></span><span class="inline-wrap">：记录和流式传输任何链式组装的中间步骤。</span></li></ol><h4 id="jsaQqraV6m9sycUbwzTvF5" class="wolai-block"><span class="inline-wrap">2.1 模型输入/输出（Model I/O）</span></h4><div id="hoyoppLERj4ftGsk3XeF5X" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 中模型输入/输出模块</span><span class="red inline-wrap"><b>是与各种大语言模型进行交互的基本组件，是大语言模型应 用的核心元素</b></span><span class="inline-wrap">。该模块的基本流程如图所示。</span></div></div><div id="smodMU45hLtotWDS8HuCiz" class="wolai-block wolai-text"><div><span class="inline-wrap">主要包含以下部分：</span><span class="red inline-wrap"><b>Prompts</b></span><span class="inline-wrap">、</span><span class="red inline-wrap"><b>Language Models</b></span><span class="inline-wrap"> 以 及 </span><span class="red inline-wrap"><b>Output Parsers</b></span><span class="inline-wrap">。用户原始输入与模型和示例进行组合，然后输入给大语言模型，再根据大语言 模型的返回结果进行输出或者结构化处理。</span></div></div><div id="nJpjVqJaowRP6LiWHEpbWL" class="wolai-block"><figure class="wolai-center" style="width:100%"><img src="media/image.png" style="width:100%"/></figure></div><div id="cy8nCp4qd7XHtqj7FzkvU8" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Prompts </b></span><span class="inline-wrap">部分主要功能是</span><span class="yellow inline-wrap">提示词模板、提示词动态选择和输入管理</span><span class="inline-wrap">。提示词是指输入模型的内 容。该输入通常由模板、示例和用户输入的组合。LangChain 提供了几个类和函数，使得构建和处 理提示词更加容易。</span></div></div><code-block id="r3NPf61n4BMcaQLZcSQhsB" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre style="white-space:pre-wrap; word-break:break-all"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate 
template <span class="token operator">=</span> <span class="token triple-quoted-string string">""" You are a naming consultant for new companies. What is a good name for a company that makes &#123;product&#125;? """</span> 

prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>template<span class="token punctuation">)</span> 
prompt<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>product<span class="token operator">=</span><span class="token string">"colorful socks"</span><span class="token punctuation">)</span>
</pre></div></code-block><div id="2tRoWbjNsGyRhXS5i4HoXU" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Language Models </b></span><span class="inline-wrap">部分提供了</span><span class="yellow inline-wrap"><b>与大语言模型的接口</b></span><span class="inline-wrap">，LangChain 提供了两种类型模型的接口和 集成：</span></div></div><ul class="wolai-block"><li id="wUpPsXgirUf9Lu5XjVyyLT"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>LLMs</b></span><span class="inline-wrap">，接受文本字符串作为输入并返回文本字符串；</span></li><li id="nfLs8qAB94qk1eYMsGm5f4"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="yellow inline-wrap"><b>Chat Model</b></span><span class="inline-wrap">，由大语言模型支持，但接受 Chat Messages 列表作为输入并返回 Chat Message。</span></li></ul><code-block id="io8jF6DHfRAQ7L6gS3NKu9" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre style="white-space:pre-wrap; word-break:break-all"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> <span class="token punctuation">(</span>AIMessage<span class="token punctuation">,</span> HumanMessage<span class="token punctuation">,</span> SystemMessage<span class="token punctuation">)</span> 

chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
  openai_api_key<span class="token operator">=</span><span class="token string">"..."</span><span class="token punctuation">,</span> 
  temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> 
  model<span class="token operator">=</span><span class="token string">'gpt-3.5-turbo'</span> 
<span class="token punctuation">)</span> 

<span class="token comment"># HumanMessage 表示用户输入的消息，</span>
<span class="token comment"># AIMessage 表示系统回复用户的消息，</span>
<span class="token comment"># SystemMessage 表示设置的 AI 应该遵循的目标，</span>
<span class="token comment"># ChatMessage 表示任务角色的消息。</span>
messages <span class="token operator">=</span> <span class="token punctuation">[</span>
  SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a helpful assistant."</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
  HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Hi AI, how are you today?"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
  AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"I'm great thank you. How can I help you?"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
  HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"I'd like to understand string theory."</span><span class="token punctuation">)</span> 
<span class="token punctuation">]</span> 

res <span class="token operator">=</span> chat<span class="token punctuation">(</span>messages<span class="token punctuation">)</span> 
<span class="token keyword">print</span><span class="token punctuation">(</span>res<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
</pre></div></code-block><div id="6C93JLsL4w2LrH2vPrAAks" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Output Parsers</b></span><span class="inline-wrap"> 部分的目标是</span><span class="yellow inline-wrap">辅助开发者从大语言模型输出中获取比仅文本更结构化的信息</span><span class="inline-wrap">。 Output Parsers 包含很多具体的实现，但是每个都必须实现如下两个必须实现的方法：</span></div></div><ol class="wolai-block"><li id="iE2MSQcDPNt5xdSeiWZUVn"><div class="marker"></div><span class="inline-wrap">获取格式化指令（Get format instructions），返回包含语言模型输出应如何格式化的字符串的方法；解析 （Parse）</span></li><li id="iXujHF4dPYC9aQC25bHeHV"><div class="marker"></div><span class="inline-wrap">接受字符串（假设为语言模型的响应）并将其解析为某种结构的方法。以及一个可选 的方法：带提示解析（Parse with prompt），接受字符串（假设为语言模型的响应）和提示（假设 为生成此响应的提示）并将其解析为某种结构的方法。</span></li></ol><h4 id="tpwnnTAYX1ZYCdw1uY5xjJ" class="wolai-block"><span class="inline-wrap">2.2 数据连接（Data Connection）</span></h4><div id="k1rKkxmEKZte2MapcvLRM5" class="wolai-block wolai-text"><div><span class="inline-wrap">许多大语言模型应用需要用户特定的数据，这些数据不是模型的训练集的一部分。为了支持上述应用的构建，</span><span class="red inline-wrap"><b>LangChain 数据连接（Data connection）</b></span><span class="inline-wrap">模块</span><span class="yellow inline-wrap"><b>通过以下方式提供组件来加载、转换、存储和查询数据</b></span><span class="inline-wrap">：Document loaders、Document transformers、Text embedding models、Vector stores 以及 Retrievers。数据连接模块部分的基本框架如图所示。</span></div></div><div id="c84RJLtRza64tKMppAjCwm" class="wolai-block"><figure class="wolai-center" style="width:100%"><img src="media/image_1.png" style="width:100%"/></figure></div><div id="2YSKmaz9n1SZemAeLGPw4A" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Document loaders（文档加载）</b></span><span class="inline-wrap">旨在从源中加载数据构建 Document。LangChain 中 Document 是包含文本和与其关联的元数据。LangChain 中包含加载简单 txt 文件的文档加载器，用于加载任 何网页的文本内容的加载器，甚至还包含用于加载 YouTube 视频的转录稿的加载器。以下是一个 最简单的从文件中读取文本加载数据的 Document 的示例：</span></div></div><code-block id="iBW3cDg3k1mLgGSf6TNPSA" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre style="white-space:pre-wrap; word-break:break-all"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader

loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">"./index.md"</span><span class="token punctuation">)</span>
loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></div></code-block><div id="iPbVLZm9tYZdS6FWjmgE8D" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Document transformers（文档转换）</b></span><span class="inline-wrap">旨在处理文档，以完成各种转换任务，如将文档格式化为 Q&amp;A 形式，去除文档中的冗余内容等，从而更好地满足不同应用程序的需求。</span></div></div><div id="uGa43Cu58UfbT8QmEfHNsQ" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Text embedding models （文本嵌入模型）</b></span><span class="inline-wrap">旨在将非结构化文本转换为嵌入表示。基于文本的嵌入 表示，可以进行语义搜索，查找最相似的文本片段。LangChain 中的 Embeddings 类公开了两个方法：一个用于文档嵌入表示，另一个用于查询嵌入表示。前者输入多个文本，后 者输入单个文本。</span></div></div><div id="h8tf1vNjHV22c3QW42wbbe" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Vector Stores（向量存储）</b></span><span class="inline-wrap">是存储和检索非结构化数据的主要方式之一。它首先将数据转化为 嵌入表示，然后存储这些生成的嵌入向量。在查询阶段，系统会利用这些嵌入向量来检索与查询内 容“最相似”的文档。向量存储的主要任务是保存这些嵌入数据并执行基于向量的搜索。LangChain 能够与多种向量数据库集成，如 Chroma、FAISS 和 Lance 等</span></div></div><div id="3parrJPwxc6FBvkAbWvk5Q" class="wolai-block wolai-text"><div><span class="red inline-wrap"><b>Retrievers（检索器）</b></span><span class="inline-wrap">是一个接口，其功能是基于非结构化查询返回相应的文档</span></div></div><h4 id="9LdNirXpKbj2Qsr74GpZRE" class="wolai-block"><span class="inline-wrap">2.3 链（Chain）</span></h4><div id="5CxBen9BPmkjRVqjPU3bvA" class="wolai-block wolai-text"><div><span class="inline-wrap">虽然独立使用大语言模型能够应对一些简单任务，但对于更加复杂的需求，可能</span><span class="red inline-wrap"><b>需要将多个大语言模型进行链式组合，或与其他组件进行链式调用</b></span><span class="inline-wrap">。LangChain 为这种“链式”应用提供了 Chain 接口，并将该接口定义得非常通用。作为一个调用组件的序列，还可以包含其他链。基本接 口非常简单，代码如下所示：</span></div></div><code-block id="b3WAX3buYHdaeX46Eeyeyo" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre style="white-space:pre-wrap; word-break:break-all"><span class="token keyword">class</span> <span class="token class-name">Chain</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">,</span> ABC<span class="token punctuation">)</span><span class="token punctuation">:</span> 
  <span class="token triple-quoted-string string">"""Base interface that all chains should implement."""</span> 
  
  memory<span class="token punctuation">:</span> BaseMemory 
  callbacks<span class="token punctuation">:</span> Callbacks 
  <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span> 
    self<span class="token punctuation">,</span> 
    inputs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span> 
    return_only_outputs<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> 
    callbacks<span class="token punctuation">:</span> Callbacks <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
  <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">:</span> 
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></div></code-block><div id="ohoVcBZTYTgyVUGHAJSfY" class="wolai-block wolai-text"><div><span class="inline-wrap">链允许将多个组件组合在一起，创建一个单一的、连贯的应用程序。</span></div></div><h4 id="uawZ6QFT93T55iv3eQT89X" class="wolai-block"><span class="inline-wrap">2.4 记忆（Memory）</span></h4><div id="rxTCN2vqRgwbhAg73erUH7" class="wolai-block wolai-text"><div><span class="inline-wrap">在 LangChain 中，这种</span><span class="red inline-wrap"><b>存储关于过去交互的信息的能力</b></span><span class="inline-wrap">被称为“记忆”（Memory）。LangChain 中提供了许多用于向系统添加记忆的方法，可以单独使用，也可以无缝地整合到链中。</span></div></div><div id="nfJDX5kNwYfBPeDjefH3Wd" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 记忆模块的基本框架如图所示。记忆系统需要支持两个基本操作：</span><span class="red inline-wrap"><b>读取和写入</b></span><span class="inline-wrap">。 每个链都根据输入定义了核心执行逻辑。其中一些输入直接来自用户，但有些输入可以来源于记忆。在接收到初始用户输入，但在执行核心逻辑之前，链将从记忆系统中读取内容并增强用户输 入。在核心逻辑执行完毕并在返回答复之前，链会将这一轮的输入和输出都保存到记忆系统中，以 便在将来使用它们。</span></div></div><div id="haW2smxrHDmEi5XWN7ED3r" class="wolai-block"><figure class="wolai-center" style="width:100%"><img src="media/image_2.png" style="width:100%"/></figure></div><div id="tChQyj45RH3R73ei57obEd" class="wolai-block wolai-text"><div><span class="inline-wrap">简单的形式，它只是将聊天消息列表保存到缓冲区中，并将其传递到提示模板中。代码示例如下 所示：</span></div></div><code-block id="7ZKr8zLH1reGsd9fmSbyBv" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre style="white-space:pre-wrap; word-break:break-all"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferMemory 
memory <span class="token operator">=</span> ConversationBufferMemory<span class="token punctuation">(</span><span class="token punctuation">)</span> 
memory<span class="token punctuation">.</span>chat_memory<span class="token punctuation">.</span>add_user_message<span class="token punctuation">(</span><span class="token string">"hi!"</span><span class="token punctuation">)</span> 
memory<span class="token punctuation">.</span>chat_memory<span class="token punctuation">.</span>add_ai_message<span class="token punctuation">(</span><span class="token string">"whats up?"</span><span class="token punctuation">)</span></pre></div></code-block><h4 id="kaZHpnuGs7Z2A85G2CLJ" class="wolai-block"><span class="inline-wrap">2.5 智能体（Agents）</span></h4><div id="pJePHw5oeRVEA31Ugredwd" class="wolai-block wolai-text"><div><span class="inline-wrap">智能体的核心思想</span><span class="red inline-wrap"><b>是使用大语言模型来选择要执行的一系列动作</b></span><span class="inline-wrap">。在链中，操作序列是硬编码在代码中的。在智能体中，则是将大语言模型用作推理引擎，以确定要采取哪些动作以及以何种顺序采取这些动作。</span><span class="green inline-wrap"><b>智能体通过将大语言模型与动作列表结合，自动地选择最佳的动作序列，从 而实现自动化决策和行动</b></span><span class="inline-wrap">。智能体可以用于许多不同类型的应用程序，例如自动化客户服务、智 能家居等。LangChain 中智能体由如下几个核心组件构成：</span></div></div><ul class="wolai-block"><li id="caWjpmBudgf4JLENaCXT1k"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>Agent</code></span><span class="inline-wrap">：是负责</span><span class="red inline-wrap"><b>决定下一步该采取什么步骤的类</b></span><span class="inline-wrap">。由大语言模型和提示驱动。提示可以包括 智能体的个性（有助于使其以某种方式做出回应）、智能体的背景上下文（有助于提供所要求 完成的任务类型的更多上下文信息）、激发更好的推理的提示策略（例如广泛使用的 ReAct）。 </span></li><li id="8xMT1nVAmHDZpABYgMnHBq"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>Tools</code></span><span class="inline-wrap">：是</span><span class="red inline-wrap"><b>智能体调用的函数</b></span><span class="inline-wrap">。这里有两个重要的考虑因素：1）为智能体提供正确的工具访 问权限；2）用对智能体最有帮助的方式描述工具。</span></li><li id="qAL7ANPDGNZ3aXTKVAu8aZ"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>Toolkits</code></span><span class="inline-wrap">：是一组旨在一起使用以完成特定任务的工具集合，并具有方便的加载方法。通常一 个工具集中有 3-5 个工具。</span></li><li id="raR4QWSveqjro8qyDbi45z"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap"><code>AgentExecutor</code></span><span class="inline-wrap">：是智能体的运行空间，这是实际调用智能体并执行其选择的操作的部分。除 了 AgentExecutor 类外，LangChain 还支持其他智能体运行空间，包括 Plan-and-execute Agent、 Baby AGI、Auto GPT 等。</span></li></ul><h4 id="j1SiEo9pVKFobCaYiu7fky" class="wolai-block"><span class="inline-wrap">2.6 回调（Callbacks）</span></h4><div id="715m3VR7iPeoSwhzj3Bb4n" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 提供了回调系统，</span><span class="red inline-wrap"><b>允许连接到大语言模型应用程序的各个阶段</b></span><span class="inline-wrap">。这对于日志记录、 监控、流式处理和其他任务非常有用。可以通过使用 API 中提供的 callbacks 参数订阅这些事件。 CallbackHandlers 是实现 CallbackHandler 接口的对象，每个事件都可以通过一个方法订阅。当事件 触发时，CallbackManager 会调用相应事件所对应的处理程序。</span></div></div><h3 id="jiajXLbycAw4cZorqrgHMm" class="wolai-block"><span class="inline-wrap">3.一些核心概念</span></h3><h4 id="rzXdijZW1robWp4J6pW8sJ" class="wolai-block"><span class="inline-wrap">3.1 Components and Chains</span></h4><div id="eG1dAyHPmsCtW89sDiFf7g" class="wolai-block wolai-text"><div><span class="inline-wrap">在 LangChain 中，</span><span class="red inline-wrap"><b>Component 是模块化的构建块，可以组合起来创建强大的应用程序</b></span><span class="inline-wrap">。Chain 是组合在一起以完成特定任务的一系列 Components（或其他 Chain）。例如，一个 Chain 可能包括一个 Prompt 模板、一个语言模型和一个输出解析器，它们一起工作以处理用户输入、生成响应并处理输出。</span></div></div><h4 id="wJYSNdhx7RCStpyCeL5yf9" class="wolai-block"><span class="inline-wrap">3.2 Prompt Templates and Values</span></h4><div id="dCqWtRMaifkaSbVu6jn5Zx" class="wolai-block wolai-text"><div><span class="green inline-wrap"><b>Prompt Template</b></span><span class="inline-wrap"> 负责创建 PromptValue，这是最终传递给语言模型的内容。Prompt Template 有助于将用户输入和其他动态信息转换为适合语言模型的格式。</span></div></div><div id="kHztpcjmgpXYxWmghZfasM" class="wolai-block wolai-text"><div><span class="green inline-wrap"><b>PromptValues</b></span><span class="inline-wrap"> 是具有方法的类，这些方法可以转换为每个模型类型期望的确切输入类型（如文本或聊天消息）。</span></div></div><h4 id="h21brJfdr215gFNf6Ut5kL" class="wolai-block"><span class="inline-wrap">3.3 Example Selectors</span></h4><div id="kiPCgwobQPt5UtV5jhRsWK" class="wolai-block wolai-text"><div><span class="inline-wrap">当您想要在 Prompts 中动态包含示例时，Example Selectors 很有用。他们</span><span class="inline-wrap"><b>接受用户输入并返回一个示例列表以在提示中使用，使其更强大和特定于上下文。</b></span></div></div><h4 id="rnJJEeYoD1VSQ46hxgZ5Ac" class="wolai-block"><span class="inline-wrap">3.4 Output Parsers</span></h4><div id="arCQZnhryrzzJTr9vrXdpm" class="wolai-block wolai-text"><div><span class="inline-wrap">Output Parsers </span><span class="yellow inline-wrap">负责将语言模型响应构建为更有用的格式</span><span class="inline-wrap">。它们实现了两种主要方法：一种用于提供格式化指令，另一种用于将语言模型的响应解析为结构化格式。这使得在您的应用程序中处理输出数据变得更加容易。</span></div></div><h4 id="7YUCGJW1sjJ988SsQyfgWa" class="wolai-block"><span class="inline-wrap">3.5 Indexes and Retrievers</span></h4><div id="njN9KnP6w2VLVskAgr1L7E" class="wolai-block wolai-text"><div><span class="inline-wrap"><code>Index </code></span><span class="inline-wrap">是</span><span class="yellow inline-wrap"><b>一种组织文档的方式</b></span><span class="inline-wrap">，使语言模型更容易与它们交互。</span></div></div><div id="j9vLFZAxtsiGamfLmNTD7N" class="wolai-block wolai-text"><div><span class="inline-wrap"><code>检索器</code></span><span class="inline-wrap">是</span><span class="yellow inline-wrap"><b>用于获取相关文档并将它们与语言模型组合的接口</b></span><span class="inline-wrap">。LangChain 提供了用于处理不同类型的索引和检索器的工具和功能，例如矢量数据库和文本拆分器。</span></div></div><h4 id="31vFwmn1YHxTmMnsuQXu2R" class="wolai-block"><span class="inline-wrap">3.6 Chat Message History</span></h4><div id="igVoeHNTF3rJKdQyX1xT3k" class="wolai-block wolai-text"><div><span class="inline-wrap"><code>LangChain</code></span><span class="inline-wrap"> 主要</span><span class="yellow inline-wrap"><b>通过聊天界面与语言模型进行交互</b></span><span class="inline-wrap">。</span></div></div><div id="9JY3VNz5zSTTDZYVacrZEP" class="wolai-block wolai-text"><div><span class="inline-wrap">ChatMessageHistory 类负责记住所有以前的聊天交互数据，然后可以将这些交互数据传递回模型、汇总或以其他方式组合。这有助于维护上下文并提高模型对对话的理解。</span></div></div><h4 id="563mXrxQJaRcH2yDaaGWi7" class="wolai-block"><span class="inline-wrap">3.7 Agents and Toolkits</span></h4><div id="wsEmB5KywV8ikLnwHB8q1u" class="wolai-block wolai-text"><div><span class="inline-wrap"><code>Agent </code></span><span class="inline-wrap">是</span><span class="yellow inline-wrap">在 LangChain 中推动决策制定的实体</span><span class="inline-wrap">。他们可以访问一套工具，并可以根据用户输入决定调用哪个工具。Tookits 是一组工具，当它们一起使用时，可以完成特定的任务。代理执行器负责使用适当的工具运行代理。</span></div></div><h3 id="kAbt7GRzTGLhvWgcoYUXj2" class="wolai-block"><span class="inline-wrap">4.什么是 LangChain Agent?</span></h3><div id="3TZP1T6n88QYf4YTRAaX2n" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain Agent 是框架中驱动决策制定的实体。它可以访问一组工具，并可以根据用户的输入决定调用哪个工具。代理帮助构建复杂的应用程序，这些应用程序需要自适应和特定于上下文的响应。当存在取决于用户输入和其他因素的未知交互链时，它们特别有用。</span></div></div><h3 id="7LKB662ib23JZCkcedcJSG" class="wolai-block"><span class="inline-wrap">5.  什么是 LangChain model?</span></h3><div id="8DAV293q2MmojTXC41R7Yr" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain model 是一种抽象，表示框架中使用的不同类型的模型。LangChain 中的模型主要分为三类：</span></div></div><ol class="wolai-block"><li id="veb3K2tA2VVf5fUYzC9Rv5"><div class="marker"></div><span class="red inline-wrap"><b>LLM（大型语言模型）</b></span><span class="inline-wrap">：这些模型将文本字符串作为输入并返回文本字符串作为输出。它们是许多语言模型应用程序的支柱。</span></li><li id="ijQc8BrmaQZcpLCPokZrzh"><div class="marker"></div><span class="red inline-wrap"><b>聊天模型( Chat Model)</b></span><span class="inline-wrap">：聊天模型由语言模型支持，但具有更结构化的 API。他们将聊天消息列表作为输入并返回聊天消息。这使得管理对话历史记录和维护上下文变得容易。</span></li><li id="hQiLwPS1FcbjgHcp2kVVug"><div class="marker"></div><span class="red inline-wrap"><b>文本嵌入模型(Text Embedding Models)</b></span><span class="inline-wrap">：这些模型将文本作为输入并返回表示文本嵌入的浮点列表。这些嵌入可用于文档检索、聚类和相似性比较等任务。</span></li></ol><div id="84pT7HtQB7JZxwPfZKDkm5" class="wolai-block wolai-text"><div><span class="inline-wrap">开发人员可以为他们的用例选择合适的 LangChain 模型，并利用提供的组件来构建他们的应用程序。</span></div></div><h3 id="vAQG3pxgEQWFkRkBnh1ZXa" class="wolai-block"><span class="inline-wrap">6.  LangChain 包含哪些特点?</span></h3><div id="vCjRBWW774AoFoSwxyNPp" class="wolai-block wolai-text"><div><span class="inline-wrap">LangChain 旨在为六个主要领域的开发人员提供支持：</span></div></div><ol class="wolai-block"><li id="kw6tvumNsNJLom4aNqcNhr"><div class="marker"></div><span class="yellow inline-wrap"><b>LLM 和提示</b></span><span class="inline-wrap">：LangChain 使管理提示、优化它们以及为所有 LLM 创建通用界面变得容易。此外，它还包括一些用于处理 LLM 的便捷实用程序。</span></li><li id="vJuY8nbMUPaDQzJ7Q1FmcN"><div class="marker"></div><span class="yellow inline-wrap"><b>链(Chain)</b></span><span class="inline-wrap">：这些是对 LLM 或其他实用程序的调用序列。LangChain 为链提供标准接口，与各种工具集成，为流行应用提供端到端的链。</span></li><li id="mC2M2rx2NJHmBqKmdsdJGE"><div class="marker"></div><span class="yellow inline-wrap"><b>数据增强生成</b></span><span class="inline-wrap">：LangChain 使链能够与外部数据源交互以收集生成步骤的数据。例如，它可以帮助总结长文本或使用特定数据源回答问题。</span></li><li id="Sy5AvbFZBV4qDQuFt6TpM"><div class="marker"></div><span class="yellow inline-wrap"><b>Agents</b></span><span class="inline-wrap">：Agents 让 LLM 做出有关行动的决定，采取这些行动，检查结果，并继续前进直到工作完成。LangChain 提供了代理的标准接口，多种代理可供选择，以及端到端的代理示例。</span></li><li id="r19zaGjG5FyRBToRqb5vvV"><div class="marker"></div><span class="yellow inline-wrap"><b>内存</b></span><span class="inline-wrap">：LangChain 有一个标准的内存接口，有助于维护链或代理调用之间的状态。它还提供了一系列内存实现和使用内存的链或代理的示例。</span></li><li id="gU7ngdXegHQfSxj9T4FPGC"><div class="marker"></div><span class="yellow inline-wrap"><b>评估</b></span><span class="inline-wrap">：很难用传统指标评估生成模型。这就是为什么 LangChain 提供提示和链来帮助开发者自己使用 LLM 评估他们的模型。</span></li></ol><div id="3CJwAk724LUC5EeGziy3Cd" class="wolai-block wolai-text"><div><span class="inline-wrap">8.  LangChain 如何使用?</span></div><ul class="wolai-block"><li id="2HyYY9dcQoSfGofWu5LbHy"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">8.1 LangChain 如何调用 LLMs 生成回复？</span></li><li id="vYE3Z5SQteUpQdmtELRmxU"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">8.2 LangChain 如何修改 提示模板？</span></li><li id="iQ6A6h7ChgEXUGehb1fxU6"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">8.3 LangChain 如何链接多个组件处理一个特定的下游任务？</span></li><li id="8emhmDoZw1Nyx8ryjY7YMH"><div class="marker"><svg width="24" height="24" viewBox="0 0 24 24" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="M12 14.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5z"></path></svg></div><span class="inline-wrap">8.4 LangChain 如何<span class="jill"></span>Embedding &amp; vector store？</span></li></ul></div><h3 id="28ouMQ4j8CHigUmhLVcEND" class="wolai-block"><span class="inline-wrap">7.LangChain 如何使用?</span></h3><h4 id="2j6s2QDZeaeENdk7f6BqHx" class="wolai-block"><span class="inline-wrap">7.1 LangChain 如何调用 LLMs 生成回复？</span></h4><div id="t3LuiikamGgqW9gq1Sk7g9" class="wolai-block wolai-text"><div><span class="inline-wrap">要调用<span class="jill"></span>LLMs<span class="jill"></span>生成回复，可以使用<span class="jill"></span>LangChain<span class="jill"></span>框架提供的<span class="jill"></span>LLMChain<span class="jill"></span>类。LLMChain<span class="jill"></span>类是<span class="jill"></span>LangChain<span class="jill"></span>的一个组件，用于与语言模型进行交互并生成回复。以下是一个示例代码片段，展示了如何使用<span class="jill"></span>LLMChain<span class="jill"></span>类调用<span class="jill"></span>LLMs<span class="jill"></span>生成回复：</span></div></div><code-block id="44vCMqTrsKsx5CxtrNNKZK" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> LLMChain

llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>  <span class="token comment"># 创建LLM实例</span>
prompt <span class="token operator">=</span> <span class="token string">"用户的问题"</span>  <span class="token comment"># 设置用户的问题</span>

<span class="token comment"># 创建LLMChain实例</span>
chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt<span class="token punctuation">)</span>

<span class="token comment"># 调用LLMs生成回复</span>
response <span class="token operator">=</span> chain<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>  <span class="token comment"># 打印生成的回复</span></pre></div></code-block><div id="oA8RgZvUcyibYNNEHp9ANh" class="wolai-block wolai-text"><div><span class="inline-wrap">在上面的代码中，首先创建了一个<span class="jill"></span>LLM<span class="jill"></span>实例，然后设置了用户的问题作为<span class="jill"></span>LLMChain<span class="jill"></span>的<span class="jill"></span>prompt。接下来，调用<span class="jill"></span>LLMChain<span class="jill"></span>的<span class="jill"></span>generate<span class="jill"></span>方法来生成回复。最后，打印生成的回复。</span></div></div><div id="fCQm2VwCcWnRebNGK9ucn8" class="wolai-block wolai-text"><div><span class="inline-wrap">请注意，可以根据需要自定义<span class="jill"></span>LLM<span class="jill"></span>的参数，例如温度（temperature）、最大令牌数（max_tokens）等。LangChain<span class="jill"></span>文档中有关于<span class="jill"></span>LLMChain<span class="jill"></span>类和<span class="jill"></span>LLM<span class="jill"></span>参数的更多详细信息。</span></div></div><h4 id="bvFEbMvuKPjATt7Famhg9M" class="wolai-block"><span class="inline-wrap">7.2 LangChain 如何修改 提示模板？</span></h4><div id="cRkNnXKKsF2Mj9CSEpPLcf" class="wolai-block wolai-text"><div><span class="inline-wrap">要修改<span class="jill"></span>LangChain<span class="jill"></span>的提示模板，可以使用<span class="jill"></span>LangChain<span class="jill"></span>框架提供的</span><span class="inline-wrap"><code>ChatPromptTemplate</code></span><span class="inline-wrap"><b>类。</b></span><span class="inline-wrap"><code>ChatPromptTemplate</code></span><span class="inline-wrap"><b>类允许您创建自定义的聊天消息提示，并根据需要进行修改。以下是一个示例代码片段，展示了如何使用</b></span><span class="inline-wrap"><code>ChatPromptTemplate</code></span><span class="inline-wrap">类修改提示模板：</span></div></div><code-block id="mS9QGCUKAWaQciNwH3gAwC" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate

<span class="token comment"># 创建一个空的ChatPromptTemplate实例</span>
template <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 添加聊天消息提示</span>
template<span class="token punctuation">.</span>add_message<span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful AI bot."</span><span class="token punctuation">)</span>
template<span class="token punctuation">.</span>add_message<span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"Hello, how are you doing?"</span><span class="token punctuation">)</span>
template<span class="token punctuation">.</span>add_message<span class="token punctuation">(</span><span class="token string">"ai"</span><span class="token punctuation">,</span> <span class="token string">"I'm doing well, thanks!"</span><span class="token punctuation">)</span>
template<span class="token punctuation">.</span>add_message<span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"What is your name?"</span><span class="token punctuation">)</span>

<span class="token comment"># 修改提示模板</span>
template<span class="token punctuation">.</span>set_message_content<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"You are a helpful AI assistant."</span><span class="token punctuation">)</span>
template<span class="token punctuation">.</span>set_message_content<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">"What is your name? Please tell me."</span><span class="token punctuation">)</span>

<span class="token comment"># 格式化聊天消息</span>
messages <span class="token operator">=</span> template<span class="token punctuation">.</span>format_messages<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span></pre></div></code-block><div id="5MVWrcmvkKkbYUdxY9T2tb" class="wolai-block wolai-text"><div><span class="inline-wrap">在上面的代码中，首先创建了一个空的</span><span class="inline-wrap"><code>ChatPromptTemplate</code></span><span class="inline-wrap">实例。然后，使用</span><span class="inline-wrap"><code>add_message</code></span><span class="inline-wrap">方法添加了聊天消息提示。接下来，我们使用</span><span class="inline-wrap"><code>set_message_content</code></span><span class="inline-wrap">方法修改了第一个和最后一个聊天消息的内容。最后，我们使用</span><span class="inline-wrap"><code>format_messages</code></span><span class="inline-wrap">方法格式化聊天消息，并打印出来。</span></div></div><div id="hpJh82vCbJJa5pQ28Wef5G" class="wolai-block wolai-text"><div><span class="inline-wrap">请注意，可以根据需要添加、删除和修改聊天消息提示。</span><span class="inline-wrap"><code>ChatPromptTemplate</code></span><span class="inline-wrap">类提供了多种方法来操作提示模板。更多详细信息和示例代码可以在<span class="jill"></span>LangChain<span class="jill"></span>文档中找到。</span></div></div><h4 id="suNTpa3w4WYNAMpXfdZmPV" class="wolai-block"><span class="inline-wrap">7.3 LangChain 如何链接多个组件处理一个特定的下游任务？</span></h4><div id="uADRXDvZr7MHzoXAVprzgB" class="wolai-block wolai-text"><div><span class="inline-wrap">要链接多个组件处理一个特定的下游任务，可以使用<span class="jill"></span>LangChain<span class="jill"></span>框架提供的</span><span class="inline-wrap"><code>Chain</code></span><span class="inline-wrap">类。</span><span class="inline-wrap"><code>Chain</code></span><span class="inline-wrap">类允许您将多个组件连接在一起，以便按顺序处理任务。以下是一个示例代码片段，展示了如何使用</span><span class="inline-wrap"><code>Chain</code></span><span class="inline-wrap">类链接多个组件处理下游任务：</span></div></div><code-block id="5s49U4PywiMUPXKV8KtSJa" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> Chain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>components <span class="token keyword">import</span> Component1<span class="token punctuation">,</span> Component2<span class="token punctuation">,</span> Component3

<span class="token comment"># 创建组件实例</span>
component1 <span class="token operator">=</span> Component1<span class="token punctuation">(</span><span class="token punctuation">)</span>
component2 <span class="token operator">=</span> Component2<span class="token punctuation">(</span><span class="token punctuation">)</span>
component3 <span class="token operator">=</span> Component3<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 创建Chain实例并添加组件</span>
chain <span class="token operator">=</span> Chain<span class="token punctuation">(</span><span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>add_component<span class="token punctuation">(</span>component1<span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>add_component<span class="token punctuation">(</span>component2<span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>add_component<span class="token punctuation">(</span>component3<span class="token punctuation">)</span>

<span class="token comment"># 处理下游任务</span>
output <span class="token operator">=</span> chain<span class="token punctuation">.</span>process_downstream_task<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span></pre></div></code-block><div id="411muMsspQbhG98haaHs37" class="wolai-block wolai-text"><div><span class="inline-wrap">在上面的代码中，首先创建了多个组件的实例，例如</span><span class="inline-wrap"><code>Component1</code></span><span class="inline-wrap">、</span><span class="inline-wrap"><code>Component2</code></span><span class="inline-wrap">和</span><span class="inline-wrap"><code>Component3</code></span><span class="inline-wrap">。然后，创建了一个</span><span class="inline-wrap"><code>Chain</code></span><span class="inline-wrap">实例，并使用</span><span class="inline-wrap"><code>add_component</code></span><span class="inline-wrap">方法将这些组件添加到链中。最后，我们调用</span><span class="inline-wrap"><code>process_downstream_task</code></span><span class="inline-wrap">方法来处理下游任务，并打印输出结果。</span></div></div><div id="jL1mPTSfNdJE6y7a6SXCT5" class="wolai-block wolai-text"><div><span class="inline-wrap">请注意，可以根据需要添加、删除和修改组件。</span><span class="inline-wrap"><code>Chain</code></span><span class="inline-wrap">类提供了多种方法来操作链。</span></div></div><h4 id="7UdRy5Nhz6A2idUchzZhLb" class="wolai-block"><span class="inline-wrap">7.4 LangChain 如何<span class="jill"></span>Embedding &amp; vector store？</span></h4><div id="7PKSPXxJoYUf629nk1KJTK" class="wolai-block wolai-text"><div><span class="inline-wrap">要在<span class="jill"></span>LangChain<span class="jill"></span>中进行嵌入和向量存储，可以使用<span class="jill"></span>LangChain<span class="jill"></span>框架提供的</span><span class="inline-wrap"><code>Embedding</code></span><span class="inline-wrap">和</span><span class="inline-wrap"><code>VectorStore</code></span><span class="inline-wrap">类。</span><span class="inline-wrap"><code>Embedding</code></span><span class="inline-wrap">类用于将文本嵌入到向量空间中，而</span><span class="inline-wrap"><code>VectorStore</code></span><span class="inline-wrap">类用于存储和检索嵌入向量。以下是一个示例代码片段，展示了如何在<span class="jill"></span>LangChain<span class="jill"></span>中进行嵌入和向量存储：</span></div></div><code-block id="hdEUbgRzQN7Ubis3RyTeaJ" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> Embedding
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstore <span class="token keyword">import</span> VectorStore

<span class="token comment"># 创建Embedding实例</span>
embedding <span class="token operator">=</span> Embedding<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 将文本嵌入到向量空间中</span>
embedding<span class="token punctuation">.</span>embed<span class="token punctuation">(</span><span class="token string">"Hello, world!"</span><span class="token punctuation">)</span>

<span class="token comment"># 创建VectorStore实例</span>
vector_store <span class="token operator">=</span> VectorStore<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 存储嵌入向量</span>
vector_store<span class="token punctuation">.</span>store<span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">,</span> embedding<span class="token punctuation">.</span>get_embedding<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 检索嵌入向量</span>
vector <span class="token operator">=</span> vector_store<span class="token punctuation">.</span>retrieve<span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>vector<span class="token punctuation">)</span></pre></div></code-block><div id="bcADdZJD1sTFhhijZLG8e5" class="wolai-block wolai-text"><div><span class="inline-wrap">在上面的代码中，首先创建了一个**</span><span class="inline-wrap"><code>Embedding</code></span><span class="inline-wrap">实例，并使用</span><span class="inline-wrap"><code>embed</code></span><span class="inline-wrap">方法将文本嵌入到向量空间中。然后，我们创建了一个</span><span class="inline-wrap"><code>VectorStore</code></span><span class="inline-wrap">实例，并使用</span><span class="inline-wrap"><code>store</code></span><span class="inline-wrap">方法将嵌入向量存储到向量存储中。最后，使用</span><span class="inline-wrap"><code>retrieve</code></span><span class="inline-wrap">方法检索嵌入向量，并打印出来。</span></div></div><div id="h5LiEN6cyCqWHPf6EQq86s" class="wolai-block wolai-text"><div><span class="inline-wrap">请注意，可以根据需要添加、删除和修改嵌入向量。</span><span class="inline-wrap"><code>Embedding</code></span><span class="inline-wrap"><b>类和</b></span><span class="inline-wrap"><code>VectorStore</code></span><span class="inline-wrap">类提供了多种方法来操作嵌入和向量存储。</span></div></div><h3 id="4mcNHsgrDYtFNrZ7r7Ka3y" class="wolai-block"><span class="inline-wrap">8.LangChain<span class="jill"></span>知识问答实践</span></h3><div id="769uBzBh7GcoL8GDd8uGBQ" class="wolai-block wolai-text"><div><span class="inline-wrap">基于 LangChain 的知识问答系统框架如图所示。</span></div></div><div id="dLKciEYrRLxDs4z4sXRSY1" class="wolai-block"><figure class="wolai-center" style="width:100%"><img src="media/image_3.png" style="width:100%"/></figure></div><div id="wVLPuSeaFFRhUmKxr7zPsa" class="wolai-block wolai-text"><div><span class="inline-wrap">知识库问答系统主要包含以下几个主要步 骤：</span></div></div><ol class="wolai-block"><li id="adHvNr1YjAeAfzk5eVgTnB"><div class="marker"></div><span class="inline-wrap">收集领域知识数据构造知识库，这些数据应当能够尽可能的全面覆盖问答需求；</span></li><li id="dNui53mzze9iXUTTW8fgJQ"><div class="marker"></div><span class="inline-wrap">将知识库中的对非结构数据进行文本提取和文本拆分，得到文本块；</span></li><li id="2yePqyRi8vB2g1ZACQGv7v"><div class="marker"></div><span class="inline-wrap">利用嵌入向量表示模型给出 文本块嵌入表示，并利用向量数据库进行保存；</span></li><li id="2WJU1Ghbbvy639tUyMnSmQ"><div class="marker"></div><span class="inline-wrap">根据用户输入信息的嵌入表示，通过向量数据 库检索得到最相关文本片段，利用提示词模板与用户输入以及历史消息合并输入大语言模型；</span></li><li id="9SyzEeUkZ9goM1y4zubEnj"><div class="marker"></div><span class="inline-wrap">将大语言模型结果返回用户</span></li></ol><div id="omuTs4s8WStKshbVLBu4p9" class="wolai-block wolai-text"><div><span class="inline-wrap">上述过程的代码示例如下所示：</span></div></div><code-block id="dRUMmZyf7Xkq2dq6bNXawN" class="wolai-block"><div class="wolai-pre"><div data-lang="Python" class="marker"></div><pre style="white-space:pre-wrap; word-break:break-all"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> DirectoryLoader 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>openai <span class="token keyword">import</span> OpenAIEmbeddings 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> CharacterTextSplitter 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ChatVectorDBChain<span class="token punctuation">,</span> ConversationalRetrievalChain 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI 
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> RetrievalQA 

<span class="token comment"># 从本地读取相关数据 </span>
loader <span class="token operator">=</span> DirectoryLoader<span class="token punctuation">(</span> 
  <span class="token string">'./Langchain/KnowledgeBase/'</span><span class="token punctuation">,</span> glob<span class="token operator">=</span><span class="token string">'**/*.pdf'</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span><span class="token boolean">True</span> 
<span class="token punctuation">)</span> 

docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 将文件进行切分 </span>
text_splitter <span class="token operator">=</span> CharacterTextSplitter<span class="token punctuation">(</span> chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">)</span> 
docs_split <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span> 

<span class="token comment"># 初始化 OpenAI Embeddings </span>
embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span> 

<span class="token comment"># 将数据存入 Chroma 向量存储 </span>
vector_store <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span> 

<span class="token comment"># 初始化检索器，使用向量存储 </span>
retriever <span class="token operator">=</span> vector_store<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span> 
system_template <span class="token operator">=</span> <span class="token triple-quoted-string string">""" Use the following pieces of context to answer the users question. If you don't know the answer, just say that you don't know, don't try to make up an answer. Answering these questions in Chinese. 
----------
{question}
----------
{chat_history}
"""</span>

<span class="token comment"># 构建初始 Messages 列表 </span>
messages <span class="token operator">=</span> <span class="token punctuation">[</span> 
  SystemMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>system_template<span class="token punctuation">)</span><span class="token punctuation">,</span> 
  HumanMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">'{question}'</span><span class="token punctuation">)</span> 
<span class="token punctuation">]</span> 

<span class="token comment"># 初始化 Prompt 对象 </span>
prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>messages<span class="token punctuation">)</span> 

<span class="token comment"># 初始化大语言模型，使用 OpenAI API </span>
llm<span class="token operator">=</span>ChatOpenAI<span class="token punctuation">(</span>temperature<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> max_tokens<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">)</span> 

<span class="token comment"># 初始化问答链 </span>
qa <span class="token operator">=</span> ConversationalRetrievalChain<span class="token punctuation">.</span>from_llm<span class="token punctuation">(</span>llm<span class="token punctuation">,</span>retriever<span class="token punctuation">,</span>condense_question_prompt<span class="token operator">=</span>prompt<span class="token punctuation">)</span> 

chat_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> 
<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span> 
  question <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">'问题：'</span><span class="token punctuation">)</span> 
  <span class="token comment"># 开始发送问题 chat_history 为必须参数, 用于存储对话历史 </span>
  result <span class="token operator">=</span> qa<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'question'</span><span class="token punctuation">:</span> question<span class="token punctuation">,</span> <span class="token string">'chat_history'</span><span class="token punctuation">:</span> chat_history<span class="token punctuation">}</span><span class="token punctuation">)</span> 
  chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>question<span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token string">'answer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
  <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">'answer'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</pre></div></code-block><div id="8JUuoMCJFsbnjTJjKgbabo" class="wolai-block wolai-text"><div><span class="inline-wrap">c</span></div></div><div id="imCVhyVVCJsxNHCYyirPNf" class="wolai-block wolai-text"><div><span class="inline-wrap"></span><br/></div></div></article><footer></footer></body></html></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/wdn_icon.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Dongnian</div><div class="author-info__description">A salty fish swimming in the sea of deep learning!</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">87</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">11</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/wdndev"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/wdndev" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:dongnian.wang@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #24292e;"></i></a><a class="social-icon" href="https://blog.csdn.net/wdnshadow" target="_blank" title="CSDN"><i class="fas fa-rss" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Welcome to My Personal Blog! <br /> If Not, Please Visit <a target="_blank" rel="noopener" href="https://wdndev.gitee.io/"> <font color=#00BFFF>Gitee Mirror</font></a>.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#6qZxn3rdExgpRf2GapUNpy"><span class="toc-text">1.什么是 LangChain?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#qhgae5g4pQwCgkXLZH5J4z"><span class="toc-text">2. LangChain 包含哪些核心模块</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#jsaQqraV6m9sycUbwzTvF5"><span class="toc-text">2.1 模型输入&#x2F;输出（Model I&#x2F;O）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tpwnnTAYX1ZYCdw1uY5xjJ"><span class="toc-text">2.2 数据连接（Data Connection）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#9LdNirXpKbj2Qsr74GpZRE"><span class="toc-text">2.3 链（Chain）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#uawZ6QFT93T55iv3eQT89X"><span class="toc-text">2.4 记忆（Memory）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kaZHpnuGs7Z2A85G2CLJ"><span class="toc-text">2.5 智能体（Agents）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#j1SiEo9pVKFobCaYiu7fky"><span class="toc-text">2.6 回调（Callbacks）</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#jiajXLbycAw4cZorqrgHMm"><span class="toc-text">3.一些核心概念</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#rzXdijZW1robWp4J6pW8sJ"><span class="toc-text">3.1 Components and Chains</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#wJYSNdhx7RCStpyCeL5yf9"><span class="toc-text">3.2 Prompt Templates and Values</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#h21brJfdr215gFNf6Ut5kL"><span class="toc-text">3.3 Example Selectors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rnJJEeYoD1VSQ46hxgZ5Ac"><span class="toc-text">3.4 Output Parsers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7YUCGJW1sjJ988SsQyfgWa"><span class="toc-text">3.5 Indexes and Retrievers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#31vFwmn1YHxTmMnsuQXu2R"><span class="toc-text">3.6 Chat Message History</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#563mXrxQJaRcH2yDaaGWi7"><span class="toc-text">3.7 Agents and Toolkits</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kAbt7GRzTGLhvWgcoYUXj2"><span class="toc-text">4.什么是 LangChain Agent?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7LKB662ib23JZCkcedcJSG"><span class="toc-text">5.  什么是 LangChain model?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vAQG3pxgEQWFkRkBnh1ZXa"><span class="toc-text">6.  LangChain 包含哪些特点?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#28ouMQ4j8CHigUmhLVcEND"><span class="toc-text">7.LangChain 如何使用?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2j6s2QDZeaeENdk7f6BqHx"><span class="toc-text">7.1 LangChain 如何调用 LLMs 生成回复？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#bvFEbMvuKPjATt7Famhg9M"><span class="toc-text">7.2 LangChain 如何修改 提示模板？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#suNTpa3w4WYNAMpXfdZmPV"><span class="toc-text">7.3 LangChain 如何链接多个组件处理一个特定的下游任务？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#7UdRy5Nhz6A2idUchzZhLb"><span class="toc-text">7.4 LangChain 如何Embedding &amp; vector store？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4mcNHsgrDYtFNrZ7r7Ka3y"><span class="toc-text">8.LangChain知识问答实践</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/llms/llms_article/9.%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BALLM/" title="检索增强LLM">检索增强LLM</a><time datetime="2024-01-12T16:00:00.000Z" title="Created 2024-01-13 00:00:00">2024-01-13</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/llms/llms_course/6.%E6%96%87%E6%9C%AC%E7%90%86%E8%A7%A3%E5%92%8C%E7%94%9F%E6%88%90%E5%A4%A7%E6%A8%A1%E5%9E%8B/" title="LLMs公开课 - 6.文本理解和生成大模型">LLMs公开课 - 6.文本理解和生成大模型</a><time datetime="2024-01-09T16:00:00.000Z" title="Created 2024-01-10 00:00:00">2024-01-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/llms/llms_course/5.%E9%AB%98%E6%95%88%E8%AE%AD%E7%BB%83_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/" title="LLMs公开课 - 5.高效训练&amp;模型压缩">LLMs公开课 - 5.高效训练&amp;模型压缩</a><time datetime="2024-01-06T16:00:00.000Z" title="Created 2024-01-07 00:00:00">2024-01-07</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            <a class="card-more-btn" href="/categories/" title="More">
    <i class="fas fa-angle-right"></i></a>
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/Cython/"><span class="card-category-list-name">Cython</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/DSA/"><span class="card-category-list-name">DSA</span><span class="card-category-list-count">24</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/LLMs/"><span class="card-category-list-name">LLMs</span><span class="card-category-list-count">16</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/PL/"><span class="card-category-list-name">PL</span><span class="card-category-list-count">7</span></a><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/PL/Cython/"><span class="card-category-list-name">Cython</span><span class="card-category-list-count">6</span></a></li></ul></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/DSA/" style="font-size: 1.42em; color: rgb(91, 145, 17)">DSA</a><a href="/tags/RL/" style="font-size: 1.28em; color: rgb(176, 79, 19)">RL</a><a href="/tags/Transformer/" style="font-size: 1.45em; color: rgb(127, 170, 70)">Transformer</a><a href="/tags/LLMs/" style="font-size: 1.32em; color: rgb(112, 148, 55)">LLMs</a><a href="/tags/PaperReading/" style="font-size: 1.38em; color: rgb(110, 146, 60)">PaperReading</a><a href="/tags/DeepLearning/" style="font-size: 1.25em; color: rgb(90, 48, 1)">DeepLearning</a><a href="/tags/CV/" style="font-size: 1.15em; color: rgb(82, 200, 174)">CV</a><a href="/tags/GPT/" style="font-size: 1.18em; color: rgb(7, 16, 91)">GPT</a><a href="/tags/PL/" style="font-size: 1.22em; color: rgb(17, 30, 26)">PL</a><a href="/tags/leetcode/" style="font-size: 1.35em; color: rgb(106, 126, 145)">leetcode</a><a href="/tags/algo/" style="font-size: 1.15em; color: rgb(181, 144, 151)">algo</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span><a class="card-more-btn" href="/archives/" title="More">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/01/"><span class="card-archive-list-date">January 2024</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/12/"><span class="card-archive-list-date">December 2023</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/11/"><span class="card-archive-list-date">November 2023</span><span class="card-archive-list-count">26</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">October 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">September 2023</span><span class="card-archive-list-count">4</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">87</div></div><div class="webinfo-item"><div class="item-name">Run time :</div><div class="item-count" id="runtimeshow" data-publishDate="2023-05-31T16:00:00.000Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Total Count :</div><div class="item-count">411.2k</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Push :</div><div class="item-count" id="last-push-date" data-lastPushDate="2024-12-08T03:57:10.055Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2024 By Dongnian</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="translateLink" type="button" title="Switch Between Traditional Chinese And Simplified Chinese">簡</button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'oe7vzWxH80qwJJjWslYTCViT-gzGzoHsz',
      appKey: 'k89nSbK0BTbmzmpQottRHvNI',
      avatar: 'monsterid',
      serverURLs: 'https://oe7vzwxh.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script async src="/js/title.js"></script><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":180,"height":360,"hOffset":0,"vOffset":-100},"mobile":{"show":true},"react":{"opacity":0.85},"log":false});</script></body></html>